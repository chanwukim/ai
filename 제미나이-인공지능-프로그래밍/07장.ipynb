{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 라마인덱스\n",
        "\n",
        "## 라인인덱스란\n",
        "\n",
        "-   라마인덱스는 자신 또는 도메인 고유의 지식을 사용하여 전문 지식이 필요한 질의응답 챗봇을 쉽게 만들 수 있는 프레임워크\n",
        "-   LLM은 공개된 대량의 데이터를 사전 학습했기에 이를 바탕으로 문장을 생성하거나 질의응답 할 수 있지만, 회사나 개인이 보유한 공개되지 않은 정보는 학습하지 못했기에 올바르게 답변할 수 없다.\n",
        "-   **검색 증강 생성(Retrieval Augmented Generation, RAG)**: 질문과 관련된 정보를 외부에서 검색하여 가져오고, 그 정보를 대규모 언어 모델에 프롬프트로 전달하여 외부 데이터를 기반으로 한 답변을 생성하게 한다.\n",
        "-   https://github.com/run-llama/llama_index\n",
        "\n",
        "![라마인덱스구조](./IMG_4247.png)\n",
        "\n",
        "## 라마인덱스 핵심 단계\n",
        "\n",
        "1. 로딩\n",
        "2. 인덱싱\n",
        "3. 저장\n",
        "4. 쿼링\n",
        "5. 평가\n",
        "\n",
        "### 1. 로딩\n",
        "\n",
        "-   데이터 소스에서 데이터를 가져오는 단계\n",
        "-   주요 컴포넌트:\n",
        "\n",
        "| 컴포넌트  |                       설명                       |\n",
        "| :-------: | :----------------------------------------------: |\n",
        "| Document  |               데이터 소스 컨테이너               |\n",
        "|   Node    | Document를 분할한 것. 청크와 메타데이터가 포함됨 |\n",
        "| Connector | 데이터 소스에서 Document와 Node를 가져오는 모듈  |\n",
        "\n",
        "### 2. 인덱싱\n",
        "\n",
        "-   데이터 쿼리를 가능하게 하는 데이터 구조. Index를 만든다.\n",
        "-   주요 컴포넌트:\n",
        "\n",
        "| 컴포넌트  |                   설명                    |\n",
        "| :-------: | :---------------------------------------: |\n",
        "|   Index   |  데이터 쿼리를 가능하게 하는 데이터 구조  |\n",
        "| Embedding | 관련성이 높은 데이터를 찾아내는 벡터 표현 |\n",
        "\n",
        "### 3. 저장\n",
        "\n",
        "-   인덱스를 생성한 뒤 인덱스와 다른 메타데이터의 쌍을 저장함으로써 이후에 같은 인덱스를 다시 생성할 필요가 없다.\n",
        "\n",
        "### 4. 쿼링\n",
        "\n",
        "-   인덱스에 대한 쿼리를 실행하는 단계\n",
        "-   데이터베이스에서 정보를 검색하거나 조작하는 데 사용하는 명령이다.\n",
        "-   주요 컴포넌트:\n",
        "\n",
        "|       컴포넌트       |                                설명                                |\n",
        "| :------------------: | :----------------------------------------------------------------: |\n",
        "|      Retriever       | 쿼리할 때 인덱스에서 관련 데이터를 효율적으로 가져오는 방법을 정의 |\n",
        "|  Node Postprocessor  |      가져온 노드를 받아 그것들에 변환, 필터링, 리랭킹을 적용       |\n",
        "| Response Synthesizer |      사용자 쿼리와 가져온 텍스트 청크를 사용하여 응답을 생성       |\n",
        "\n",
        "### 5. 평가\n",
        "\n",
        "-   쿼리에 대한 응답이 객관적으로 평가\n",
        "    -   정확한지\n",
        "    -   충실한지\n",
        "    -   신속한지 등\n"
      ],
      "metadata": {
        "id": "IsxIRLlTQFEg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 패키지 설치\n",
        "```bash\n",
        "pip install llama-index==0.11.20\n",
        "pip install llama-index-llms-google-genai\n",
        "pip install llama-index-embeddings-hugginface\n",
        "```"
      ],
      "metadata": {
        "id": "OuOi0aGcQMmh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index-llms-google-genai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "54oxvU3BQWpt",
        "outputId": "3eef4c56-96f6-4e97-e1d0-43debc8bdf57"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-index-llms-google-genai\n",
            "  Downloading llama_index_llms_google_genai-0.7.3-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: google-genai<2,>=1.24.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-llms-google-genai) (1.49.0)\n",
            "Requirement already satisfied: llama-index-core<0.15,>=0.14.5 in /usr/local/lib/python3.12/dist-packages (from llama-index-llms-google-genai) (0.14.8)\n",
            "Requirement already satisfied: pillow>=10.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-llms-google-genai) (10.4.0)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2,>=1.24.0->llama-index-llms-google-genai) (4.11.0)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-genai<2,>=1.24.0->llama-index-llms-google-genai) (2.38.0)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai<2,>=1.24.0->llama-index-llms-google-genai) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2,>=1.24.0->llama-index-llms-google-genai) (2.11.10)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai<2,>=1.24.0->llama-index-llms-google-genai) (2.32.4)\n",
            "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from google-genai<2,>=1.24.0->llama-index-llms-google-genai) (8.5.0)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2,>=1.24.0->llama-index-llms-google-genai) (15.0.1)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2,>=1.24.0->llama-index-llms-google-genai) (4.15.0)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.6 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (3.13.2)\n",
            "Requirement already satisfied: aiosqlite in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (0.21.0)\n",
            "Requirement already satisfied: banks<3,>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (2.2.0)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (1.3.1)\n",
            "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (1.0.8)\n",
            "Requirement already satisfied: filetype<2,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (2025.3.0)\n",
            "Requirement already satisfied: llama-index-workflows!=2.9.0,<3,>=2 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (2.11.1)\n",
            "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (3.5)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (1.26.4)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (4.5.0)\n",
            "Requirement already satisfied: pyyaml>=6.0.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (6.0.3)\n",
            "Requirement already satisfied: setuptools>=80.9.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (80.9.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.49 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (2.0.44)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (0.12.0)\n",
            "Requirement already satisfied: tqdm<5,>=4.66.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (4.67.1)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (2.0.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (1.22.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai<2,>=1.24.0->llama-index-llms-google-genai) (3.11)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai<2,>=1.24.0->llama-index-llms-google-genai) (1.3.1)\n",
            "Requirement already satisfied: griffe in /usr/local/lib/python3.12/dist-packages (from banks<3,>=2.2.0->llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (1.15.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from banks<3,>=2.2.0->llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (3.1.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai<2,>=1.24.0->llama-index-llms-google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai<2,>=1.24.0->llama-index-llms-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai<2,>=1.24.0->llama-index-llms-google-genai) (4.9.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2,>=1.24.0->llama-index-llms-google-genai) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2,>=1.24.0->llama-index-llms-google-genai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai<2,>=1.24.0->llama-index-llms-google-genai) (0.16.0)\n",
            "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-workflows!=2.9.0,<3,>=2->llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (0.4.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (8.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (2024.11.6)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.9.0->google-genai<2,>=1.24.0->llama-index-llms-google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.9.0->google-genai<2,>=1.24.0->llama-index-llms-google-genai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.9.0->google-genai<2,>=1.24.0->llama-index-llms-google-genai) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai<2,>=1.24.0->llama-index-llms-google-genai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai<2,>=1.24.0->llama-index-llms-google-genai) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (3.2.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (1.1.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json->llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (3.26.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.12/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (25.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-genai<2,>=1.24.0->llama-index-llms-google-genai) (0.6.1)\n",
            "Requirement already satisfied: colorama>=0.4 in /usr/local/lib/python3.12/dist-packages (from griffe->banks<3,>=2.2.0->llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->banks<3,>=2.2.0->llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (3.0.3)\n",
            "Downloading llama_index_llms_google_genai-0.7.3-py3-none-any.whl (13 kB)\n",
            "Installing collected packages: llama-index-llms-google-genai\n",
            "Successfully installed llama-index-llms-google-genai-0.7.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "llama_index"
                ]
              },
              "id": "4cb520175cb24db4997f60f6bf46a892"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import sys\n",
        "\n",
        "logging.basicConfig(stream=sys.stdout, level=logging.DEBUG, force=True)"
      ],
      "metadata": {
        "id": "WQkUU_y8ROQ0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import Settings\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from llama_index.llms.google_genai import GoogleGenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "import logging\n",
        "import sys\n",
        "logging.basicConfig(stream=sys.stdout, level=logging.DEBUG, force=True)\n",
        "\n",
        "# LLM 모델 준비\n",
        "Settings.llm = GoogleGenAI(\n",
        "    model_name=\"models/gemini-2.5-flash\",\n",
        "    api_key=userdata.get('GOOGLE_API_KEY'),\n",
        "    safety_settings={\n",
        "        \"HARM_CATEGORY_HARASSMENT\": \"BLOCK_NONE\",\n",
        "        \"HARM_CATEGORY_HATE_SPEECH\": \"BLOCK_NONE\",\n",
        "        \"HARM_CATEGORY_SEXUALLY_EXPLICIT\": \"BLOCK_NONE\",\n",
        "        \"HARM_CATEGORY_DANGEROUS_CONTENT\": \"BLOCK_NONE\"\n",
        "    }\n",
        ")\n",
        "\n",
        "# 임베딜 모델 준비\n",
        "Settings.embed_model = HuggingFaceEmbedding(\n",
        "    model_name=\"BAAI/bge-m3\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPCc3-zGRX6V",
        "outputId": "ab31626e-9a3c-4eaf-8f08-f64d4e90baaa"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEBUG:httpcore.connection:connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None\n",
            "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7b922cd6f320>\n",
            "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x7b922cff0550> server_hostname='generativelanguage.googleapis.com' timeout=None\n",
            "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7b922cd6f290>\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'GET']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'GET']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'GET']>\n",
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Mon, 17 Nov 2025 15:11:17 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=185'), (b'Transfer-Encoding', b'chunked')])\n",
            "INFO:httpx:HTTP Request: GET https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash \"HTTP/1.1 200 OK\"\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'GET']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n",
            "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: BAAI/bge-m3\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /BAAI/bge-m3/resolve/main/modules.json HTTP/1.1\" 307 0\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /api/resolve-cache/models/BAAI/bge-m3/5617a9f61b028005a4858fdac845db406aefb181/modules.json HTTP/1.1\" 200 0\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /BAAI/bge-m3/resolve/main/config_sentence_transformers.json HTTP/1.1\" 307 0\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /api/resolve-cache/models/BAAI/bge-m3/5617a9f61b028005a4858fdac845db406aefb181/config_sentence_transformers.json HTTP/1.1\" 200 0\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /BAAI/bge-m3/resolve/main/config_sentence_transformers.json HTTP/1.1\" 307 0\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /api/resolve-cache/models/BAAI/bge-m3/5617a9f61b028005a4858fdac845db406aefb181/config_sentence_transformers.json HTTP/1.1\" 200 0\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /BAAI/bge-m3/resolve/main/README.md HTTP/1.1\" 307 0\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /api/resolve-cache/models/BAAI/bge-m3/5617a9f61b028005a4858fdac845db406aefb181/README.md HTTP/1.1\" 200 0\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /BAAI/bge-m3/resolve/main/modules.json HTTP/1.1\" 307 0\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /api/resolve-cache/models/BAAI/bge-m3/5617a9f61b028005a4858fdac845db406aefb181/modules.json HTTP/1.1\" 200 0\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /BAAI/bge-m3/resolve/main/sentence_bert_config.json HTTP/1.1\" 307 0\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /api/resolve-cache/models/BAAI/bge-m3/5617a9f61b028005a4858fdac845db406aefb181/sentence_bert_config.json HTTP/1.1\" 200 0\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /BAAI/bge-m3/resolve/main/adapter_config.json HTTP/1.1\" 404 0\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /BAAI/bge-m3/resolve/main/config.json HTTP/1.1\" 307 0\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /api/resolve-cache/models/BAAI/bge-m3/5617a9f61b028005a4858fdac845db406aefb181/config.json HTTP/1.1\" 200 0\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /BAAI/bge-m3/resolve/main/model.safetensors HTTP/1.1\" 404 0\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /api/models/BAAI/bge-m3 HTTP/1.1\" 200 5134\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /api/models/BAAI/bge-m3/commits/main HTTP/1.1\" 200 9525\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /api/models/BAAI/bge-m3/discussions?p=0 HTTP/1.1\" 200 30543\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /api/models/BAAI/bge-m3/commits/refs%2Fpr%2F130 HTTP/1.1\" 200 10490\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /BAAI/bge-m3/resolve/refs%2Fpr%2F130/model.safetensors.index.json HTTP/1.1\" 404 0\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /BAAI/bge-m3/resolve/refs%2Fpr%2F130/model.safetensors HTTP/1.1\" 302 0\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /BAAI/bge-m3/resolve/main/tokenizer_config.json HTTP/1.1\" 307 0\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /api/resolve-cache/models/BAAI/bge-m3/5617a9f61b028005a4858fdac845db406aefb181/tokenizer_config.json HTTP/1.1\" 200 0\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /api/models/BAAI/bge-m3/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1\" 404 64\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /BAAI/bge-m3/resolve/main/1_Pooling/config.json HTTP/1.1\" 307 0\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /api/resolve-cache/models/BAAI/bge-m3/5617a9f61b028005a4858fdac845db406aefb181/1_Pooling%2Fconfig.json HTTP/1.1\" 200 0\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /api/models/BAAI/bge-m3 HTTP/1.1\" 200 5134\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import SimpleDirectoryReader\n",
        "\n",
        "documents = SimpleDirectoryReader('./data').load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YBeziX3TbD1",
        "outputId": "bf5acbfa-bfa0-4084-9849-fabbf2e478d5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEBUG:llama_index.core.readers.file.base:> [SimpleDirectoryReader] Total files added: 7\n",
            "DEBUG:fsspec.local:open file: /content/data/redhood1.txt\n",
            "DEBUG:fsspec.local:open file: /content/data/redhood2.txt\n",
            "DEBUG:fsspec.local:open file: /content/data/redhood3.txt\n",
            "DEBUG:fsspec.local:open file: /content/data/redhood4.txt\n",
            "DEBUG:fsspec.local:open file: /content/data/redhood5.txt\n",
            "DEBUG:fsspec.local:open file: /content/data/redhood6.txt\n",
            "DEBUG:fsspec.local:open file: /content/data/redhood7.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 인덱스 생성하기\n",
        "# 문서를 청크로 분할하고, 청크 단위로 데이터를 임베딩으로 변환해서 유지\n",
        "# 청크는 유사도 검색 대상이 되는 데이터\n",
        "\n",
        "from llama_index.core import VectorStoreIndex\n",
        "\n",
        "index = VectorStoreIndex.from_documents(documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euZkLYpxTkgh",
        "outputId": "5e582c6a-5ff0-4e09-b26c-5f4eae160e85"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 1장: 밤의 도시, 네온 불빛 아래에서\r\n",
            "장소: 2077년, 밤의 도시, 네온 불빛이...\n",
            "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 2장: 잭과의 만남, 위험한 동행\n",
            "장소: 은비의 은신처, 폐허가 된 건물\n",
            "\n",
            "은비...\n",
            "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 3장: 아크 코퍼레이션 잠입 작전\n",
            "장소: 아크 코퍼레이션 본사, 최첨단 보안 시스템...\n",
            "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 4장: 데이터의 바다에서 진실을 찾아서\n",
            "장소: 아크 코퍼레이션 데이터 센터\n",
            "\n",
            "은...\n",
            "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 5장: 추격과 탈출\n",
            "장소: 도시의 뒷골목, 고속도로\n",
            "\n",
            "아크 코퍼레이션의 추격대가...\n",
            "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 6장: 세상에 알리다\n",
            "장소: 은비의 블로그\n",
            "\n",
            "은비는 자신이 얻은 증거를 바탕으로...\n",
            "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 7장: 새로운 시작\n",
            "장소: 폐허가 된 건물\n",
            "\n",
            "은비와 잭은 다시 낡은 건물의 지하...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 쿼리 엔진 작성하기\n",
        "\n",
        "# 사용자 입력과 관련된 정보를 인덱스에서 가져와 사용자 입력과 얻은 정보를 바탕으로 응답을 생성하는 모듈\n",
        "\n",
        "query_engine = index.as_query_engine()"
      ],
      "metadata": {
        "id": "bEirQGf5TzcR"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install nest_asyncio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7ZLi0RJU7g-",
        "outputId": "dd396e7d-0f3f-4604-f836-3bdcccc9e1d6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.12/dist-packages (1.6.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<frozen posixpath>:82: RuntimeWarning: coroutine 'prepare_chat_params' was never awaited\n",
            "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "MeXMFaCOU--4"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(query_engine.query(\"은비의 나이는?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R24JzpBjT9dq",
        "outputId": "35f01c8f-ce84-4110-c9fc-2d2b482a0589"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEBUG:llama_index.core.indices.utils:> Top 2 nodes:\n",
            "> [Node ad17e73a-4f61-4088-ad6e-7ebf175f8682] [Similarity score:                 0.536515] 1장: 밤의 도시, 네온 불빛 아래에서\r\n",
            "장소: 2077년, 밤의 도시, 네온 불빛이 가득한 뒷골목\r\n",
            "\r\n",
            "등장인물: 은비(17세, 해커), 잭(은비의 파트너, 전직 용병)\r\n",
            "...\n",
            "> [Node 07bee9e8-9773-480f-8222-086689aaa32c] [Similarity score:                 0.447299] 2장: 잭과의 만남, 위험한 동행\r\n",
            "장소: 은비의 은신처, 폐허가 된 건물\r\n",
            "\r\n",
            "은비는 낡은 건물의 지하실에 도착했다. 그곳에는 잭이 기다리고 있었다. 잭은 거대한 체구에 온...\n",
            "INFO:google_genai.models:AFC is enabled with max remote calls: 10.\n",
            "DEBUG:httpcore.connection:close.started\n",
            "DEBUG:httpcore.connection:close.complete\n",
            "DEBUG:httpcore.connection:connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None\n",
            "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x780bdeb07b90>\n",
            "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x780bf810ced0> server_hostname='generativelanguage.googleapis.com' timeout=None\n",
            "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x780bf9120b90>\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Mon, 17 Nov 2025 14:59:37 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=673'), (b'Transfer-Encoding', b'chunked')])\n",
            "INFO:httpx:HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n",
            "은비는 17세이다.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(query_engine.query(\"은비가 은신처에서 만난 인물은?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbvKz7acVCt8",
        "outputId": "3cfa5610-f96c-49c7-962f-422f45318387"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEBUG:llama_index.core.indices.utils:> Top 2 nodes:\n",
            "> [Node 07bee9e8-9773-480f-8222-086689aaa32c] [Similarity score:                 0.523242] 2장: 잭과의 만남, 위험한 동행\r\n",
            "장소: 은비의 은신처, 폐허가 된 건물\r\n",
            "\r\n",
            "은비는 낡은 건물의 지하실에 도착했다. 그곳에는 잭이 기다리고 있었다. 잭은 거대한 체구에 온...\n",
            "> [Node ad17e73a-4f61-4088-ad6e-7ebf175f8682] [Similarity score:                 0.481006] 1장: 밤의 도시, 네온 불빛 아래에서\r\n",
            "장소: 2077년, 밤의 도시, 네온 불빛이 가득한 뒷골목\r\n",
            "\r\n",
            "등장인물: 은비(17세, 해커), 잭(은비의 파트너, 전직 용병)\r\n",
            "...\n",
            "INFO:google_genai.models:AFC is enabled with max remote calls: 10.\n",
            "DEBUG:httpcore.connection:close.started\n",
            "DEBUG:httpcore.connection:close.complete\n",
            "DEBUG:httpcore.connection:connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None\n",
            "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x780bdec2ea50>\n",
            "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x780bf810ced0> server_hostname='generativelanguage.googleapis.com' timeout=None\n",
            "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x780bdeb06f00>\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Mon, 17 Nov 2025 14:59:56 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=713'), (b'Transfer-Encoding', b'chunked')])\n",
            "INFO:httpx:HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n",
            "은비는 은신처에서 잭을 만났다.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 인덱스 저장하기\n",
        "# 다음에 사용할 때 같은 인덱스를 다시 작성하지 않아도 되어 시간과 비용을 줄임\n",
        "\n",
        "index.storage_context.persist()\n",
        "\n",
        "#  ./storage에 인덱스 정보가 저장됨"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PP-YPSEiVJ5l",
        "outputId": "36c01a5e-0543-478e-dc2d-79ebcab5b387"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEBUG:fsspec.local:open file: /content/storage/docstore.json\n",
            "DEBUG:fsspec.local:open file: /content/storage/index_store.json\n",
            "DEBUG:fsspec.local:open file: /content/storage/graph_store.json\n",
            "DEBUG:fsspec.local:open file: /content/storage/default__vector_store.json\n",
            "DEBUG:fsspec.local:open file: /content/storage/image__vector_store.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 인덱스 불러오기\n",
        "\n",
        "from llama_index.core import StorageContext, load_index_from_storage\n",
        "\n",
        "storage_context = StorageContext.from_defaults(persist_dir=\"./storage\")\n",
        "index = load_index_from_storage(storage_context)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpzHEXndVZwM",
        "outputId": "59046add-16bc-495b-db19-6375c32496b8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEBUG:llama_index.core.storage.kvstore.simple_kvstore:Loading llama_index.core.storage.kvstore.simple_kvstore from ./storage/docstore.json.\n",
            "DEBUG:fsspec.local:open file: /content/storage/docstore.json\n",
            "DEBUG:llama_index.core.storage.kvstore.simple_kvstore:Loading llama_index.core.storage.kvstore.simple_kvstore from ./storage/index_store.json.\n",
            "DEBUG:fsspec.local:open file: /content/storage/index_store.json\n",
            "DEBUG:llama_index.core.graph_stores.simple:Loading llama_index.core.graph_stores.simple from ./storage/graph_store.json.\n",
            "DEBUG:fsspec.local:open file: /content/storage/graph_store.json\n",
            "DEBUG:fsspec.local:open file: /content/storage/property_graph_store.json\n",
            "DEBUG:llama_index.core.vector_stores.simple:Loading llama_index.core.vector_stores.simple from ./storage/image__vector_store.json.\n",
            "DEBUG:fsspec.local:open file: /content/storage/image__vector_store.json\n",
            "DEBUG:llama_index.core.vector_stores.simple:Loading llama_index.core.vector_stores.simple from ./storage/default__vector_store.json.\n",
            "DEBUG:fsspec.local:open file: /content/storage/default__vector_store.json\n",
            "INFO:llama_index.core.indices.loading:Loading all indices.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 리랭커\n",
        "Recranker는 가져온 정보를 순위별로 나열해서 관련성이 높은 정보를 추출하는 모델이다.\n",
        "벡터 검색과 비교하면 처리 속도는 느리지만 더 정확하다.\n",
        "따라서 먼저 벡터 검색으로 정보를 걸러 낸 뒤 리랭커로 정보를 선별하는 방법을 권장\n",
        "\n",
        "1. 벡터 검색으로 질문과 관련된 정보를 가져온다.\n",
        "2. 리랭커로 정보 순위를 매긴다.\n",
        "3. 상위 N개의 정보를 사용해 질문에 대한 답변을 생성한다."
      ],
      "metadata": {
        "id": "j4UDbXYdWAhs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index-postprocessor-flag-embedding-reranker\n",
        "!pip install FlagEmbedding\n",
        "!pip install peft"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CsT5mzTWTsx",
        "outputId": "8ed52a12-f082-4993-e01b-2414acf1d837"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: llama-index-postprocessor-flag-embedding-reranker in /usr/local/lib/python3.12/dist-packages (0.4.1)\n",
            "Requirement already satisfied: llama-index-core<0.15,>=0.13.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-postprocessor-flag-embedding-reranker) (0.14.8)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.6 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-postprocessor-flag-embedding-reranker) (3.13.2)\n",
            "Requirement already satisfied: aiosqlite in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-postprocessor-flag-embedding-reranker) (0.21.0)\n",
            "Requirement already satisfied: banks<3,>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-postprocessor-flag-embedding-reranker) (2.2.0)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-postprocessor-flag-embedding-reranker) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-postprocessor-flag-embedding-reranker) (1.3.1)\n",
            "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-postprocessor-flag-embedding-reranker) (1.0.8)\n",
            "Requirement already satisfied: filetype<2,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-postprocessor-flag-embedding-reranker) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-postprocessor-flag-embedding-reranker) (2025.3.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-postprocessor-flag-embedding-reranker) (0.28.1)\n",
            "Requirement already satisfied: llama-index-workflows!=2.9.0,<3,>=2 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-postprocessor-flag-embedding-reranker) (2.11.1)\n",
            "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-postprocessor-flag-embedding-reranker) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-postprocessor-flag-embedding-reranker) (3.5)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-postprocessor-flag-embedding-reranker) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-postprocessor-flag-embedding-reranker) (1.26.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-postprocessor-flag-embedding-reranker) (10.4.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-postprocessor-flag-embedding-reranker) (4.5.0)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-postprocessor-flag-embedding-reranker) (2.11.10)\n",
            "Requirement already satisfied: pyyaml>=6.0.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-postprocessor-flag-embedding-reranker) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-postprocessor-flag-embedding-reranker) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=80.9.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-postprocessor-flag-embedding-reranker) (80.9.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.49 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15,>=0.13.0->llama-index-postprocessor-flag-embedding-reranker) (2.0.44)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-postprocessor-flag-embedding-reranker) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-postprocessor-flag-embedding-reranker) (0.12.0)\n",
            "Requirement already satisfied: tqdm<5,>=4.66.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-postprocessor-flag-embedding-reranker) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-postprocessor-flag-embedding-reranker) (4.15.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-postprocessor-flag-embedding-reranker) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-postprocessor-flag-embedding-reranker) (2.0.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-postprocessor-flag-embedding-reranker) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-postprocessor-flag-embedding-reranker) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-postprocessor-flag-embedding-reranker) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-postprocessor-flag-embedding-reranker) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-postprocessor-flag-embedding-reranker) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-postprocessor-flag-embedding-reranker) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-postprocessor-flag-embedding-reranker) (1.22.0)\n",
            "Requirement already satisfied: griffe in /usr/local/lib/python3.12/dist-packages (from banks<3,>=2.2.0->llama-index-core<0.15,>=0.13.0->llama-index-postprocessor-flag-embedding-reranker) (1.15.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from banks<3,>=2.2.0->llama-index-core<0.15,>=0.13.0->llama-index-postprocessor-flag-embedding-reranker) (3.1.6)\n",
            "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-workflows!=2.9.0,<3,>=2->llama-index-core<0.15,>=0.13.0->llama-index-postprocessor-flag-embedding-reranker) (0.4.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama-index-core<0.15,>=0.13.0->llama-index-postprocessor-flag-embedding-reranker) (8.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama-index-core<0.15,>=0.13.0->llama-index-postprocessor-flag-embedding-reranker) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama-index-core<0.15,>=0.13.0->llama-index-postprocessor-flag-embedding-reranker) (2024.11.6)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.8.0->llama-index-core<0.15,>=0.13.0->llama-index-postprocessor-flag-embedding-reranker) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.8.0->llama-index-core<0.15,>=0.13.0->llama-index-postprocessor-flag-embedding-reranker) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.8.0->llama-index-core<0.15,>=0.13.0->llama-index-postprocessor-flag-embedding-reranker) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31.0->llama-index-core<0.15,>=0.13.0->llama-index-postprocessor-flag-embedding-reranker) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31.0->llama-index-core<0.15,>=0.13.0->llama-index-postprocessor-flag-embedding-reranker) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31.0->llama-index-core<0.15,>=0.13.0->llama-index-postprocessor-flag-embedding-reranker) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31.0->llama-index-core<0.15,>=0.13.0->llama-index-postprocessor-flag-embedding-reranker) (2025.10.5)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15,>=0.13.0->llama-index-postprocessor-flag-embedding-reranker) (3.2.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.15,>=0.13.0->llama-index-postprocessor-flag-embedding-reranker) (1.1.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json->llama-index-core<0.15,>=0.13.0->llama-index-postprocessor-flag-embedding-reranker) (3.26.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx->llama-index-core<0.15,>=0.13.0->llama-index-postprocessor-flag-embedding-reranker) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx->llama-index-core<0.15,>=0.13.0->llama-index-postprocessor-flag-embedding-reranker) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.15,>=0.13.0->llama-index-postprocessor-flag-embedding-reranker) (0.16.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.12/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.15,>=0.13.0->llama-index-postprocessor-flag-embedding-reranker) (25.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx->llama-index-core<0.15,>=0.13.0->llama-index-postprocessor-flag-embedding-reranker) (1.3.1)\n",
            "Requirement already satisfied: colorama>=0.4 in /usr/local/lib/python3.12/dist-packages (from griffe->banks<3,>=2.2.0->llama-index-core<0.15,>=0.13.0->llama-index-postprocessor-flag-embedding-reranker) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->banks<3,>=2.2.0->llama-index-core<0.15,>=0.13.0->llama-index-postprocessor-flag-embedding-reranker) (3.0.3)\n",
            "Collecting FlagEmbedding\n",
            "  Downloading FlagEmbedding-1.3.5.tar.gz (163 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.9/163.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from FlagEmbedding) (2.8.0+cu126)\n",
            "Requirement already satisfied: transformers>=4.44.2 in /usr/local/lib/python3.12/dist-packages (from FlagEmbedding) (4.57.1)\n",
            "Requirement already satisfied: datasets>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from FlagEmbedding) (4.0.0)\n",
            "Requirement already satisfied: accelerate>=0.20.1 in /usr/local/lib/python3.12/dist-packages (from FlagEmbedding) (1.11.0)\n",
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.12/dist-packages (from FlagEmbedding) (5.1.2)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (from FlagEmbedding) (0.17.1)\n",
            "Collecting ir-datasets (from FlagEmbedding)\n",
            "  Downloading ir_datasets-0.5.11-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from FlagEmbedding) (0.2.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from FlagEmbedding) (5.29.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.20.1->FlagEmbedding) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.20.1->FlagEmbedding) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.20.1->FlagEmbedding) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.20.1->FlagEmbedding) (6.0.3)\n",
            "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.20.1->FlagEmbedding) (0.36.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.20.1->FlagEmbedding) (0.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.19.0->FlagEmbedding) (3.20.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.19.0->FlagEmbedding) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.19.0->FlagEmbedding) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets>=2.19.0->FlagEmbedding) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.19.0->FlagEmbedding) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.19.0->FlagEmbedding) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets>=2.19.0->FlagEmbedding) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.19.0->FlagEmbedding) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.19.0->FlagEmbedding) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->FlagEmbedding) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->FlagEmbedding) (80.9.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->FlagEmbedding) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->FlagEmbedding) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->FlagEmbedding) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->FlagEmbedding) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->FlagEmbedding) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->FlagEmbedding) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->FlagEmbedding) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->FlagEmbedding) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->FlagEmbedding) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->FlagEmbedding) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->FlagEmbedding) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->FlagEmbedding) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->FlagEmbedding) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->FlagEmbedding) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->FlagEmbedding) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->FlagEmbedding) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->FlagEmbedding) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->FlagEmbedding) (3.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.44.2->FlagEmbedding) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.44.2->FlagEmbedding) (0.22.1)\n",
            "Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.12/dist-packages (from ir-datasets->FlagEmbedding) (4.13.5)\n",
            "Collecting inscriptis>=2.2.0 (from ir-datasets->FlagEmbedding)\n",
            "  Downloading inscriptis-2.6.0-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: lxml>=4.5.2 in /usr/local/lib/python3.12/dist-packages (from ir-datasets->FlagEmbedding) (5.4.0)\n",
            "Collecting trec-car-tools>=2.5.4 (from ir-datasets->FlagEmbedding)\n",
            "  Downloading trec_car_tools-2.6-py3-none-any.whl.metadata (640 bytes)\n",
            "Collecting lz4>=3.1.10 (from ir-datasets->FlagEmbedding)\n",
            "  Downloading lz4-4.4.5-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting warc3-wet>=0.2.3 (from ir-datasets->FlagEmbedding)\n",
            "  Downloading warc3_wet-0.2.5-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting warc3-wet-clueweb09>=0.2.5 (from ir-datasets->FlagEmbedding)\n",
            "  Downloading warc3-wet-clueweb09-0.2.5.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting zlib-state>=0.1.3 (from ir-datasets->FlagEmbedding)\n",
            "  Downloading zlib_state-0.1.10-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (3.5 kB)\n",
            "Collecting ijson>=3.1.3 (from ir-datasets->FlagEmbedding)\n",
            "  Downloading ijson-3.4.0.post0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (23 kB)\n",
            "Collecting unlzw3>=0.2.1 (from ir-datasets->FlagEmbedding)\n",
            "  Downloading unlzw3-0.2.3-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence_transformers->FlagEmbedding) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence_transformers->FlagEmbedding) (1.16.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence_transformers->FlagEmbedding) (10.4.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.4.1->ir-datasets->FlagEmbedding) (2.8)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.19.0->FlagEmbedding) (3.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate>=0.20.1->FlagEmbedding) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=2.19.0->FlagEmbedding) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=2.19.0->FlagEmbedding) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=2.19.0->FlagEmbedding) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=2.19.0->FlagEmbedding) (2025.10.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.6.0->FlagEmbedding) (1.3.0)\n",
            "Collecting cbor>=1.0.0 (from trec-car-tools>=2.5.4->ir-datasets->FlagEmbedding)\n",
            "  Downloading cbor-1.0.0.tar.gz (20 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.6.0->FlagEmbedding) (3.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=2.19.0->FlagEmbedding) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=2.19.0->FlagEmbedding) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=2.19.0->FlagEmbedding) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence_transformers->FlagEmbedding) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence_transformers->FlagEmbedding) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.19.0->FlagEmbedding) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.19.0->FlagEmbedding) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.19.0->FlagEmbedding) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.19.0->FlagEmbedding) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.19.0->FlagEmbedding) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.19.0->FlagEmbedding) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.19.0->FlagEmbedding) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.19.0->FlagEmbedding) (1.17.0)\n",
            "Downloading ir_datasets-0.5.11-py3-none-any.whl (866 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m866.1/866.1 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ijson-3.4.0.post0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (149 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.0/149.0 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading inscriptis-2.6.0-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.1/45.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lz4-4.4.5-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trec_car_tools-2.6-py3-none-any.whl (8.4 kB)\n",
            "Downloading unlzw3-0.2.3-py3-none-any.whl (6.7 kB)\n",
            "Downloading warc3_wet-0.2.5-py3-none-any.whl (18 kB)\n",
            "Downloading zlib_state-0.1.10-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (22 kB)\n",
            "Building wheels for collected packages: FlagEmbedding, warc3-wet-clueweb09, cbor\n",
            "  Building wheel for FlagEmbedding (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for FlagEmbedding: filename=flagembedding-1.3.5-py3-none-any.whl size=233822 sha256=1aa8d6a36f50d841e490b39e5606ef895d0e4f3494b08a8a60fae7d769ee08e9\n",
            "  Stored in directory: /root/.cache/pip/wheels/b2/1f/f6/78f862bb80cb959cc9960b7c4e2d1f702b1bc0e79d19b5f124\n",
            "  Building wheel for warc3-wet-clueweb09 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for warc3-wet-clueweb09: filename=warc3_wet_clueweb09-0.2.5-py3-none-any.whl size=18997 sha256=f2ba352252f0a71882d289613fe56e535ec492cd6ecf4a7a76a50778d3ea363e\n",
            "  Stored in directory: /root/.cache/pip/wheels/f6/85/c2/9f0f621def52a1d5db7d29984f81e45f9fb6dfeb1a4eb6e31c\n",
            "  Building wheel for cbor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cbor: filename=cbor-1.0.0-cp312-cp312-linux_x86_64.whl size=55065 sha256=f96ddb5575c0088b09656fdeef45929f62a8c2b93a49c47376ad3f0c008ca351\n",
            "  Stored in directory: /root/.cache/pip/wheels/44/3e/21/a739cbcc331a1ab45c326d6edbdac6118de4402f6076e30ff1\n",
            "Successfully built FlagEmbedding warc3-wet-clueweb09 cbor\n",
            "Installing collected packages: warc3-wet-clueweb09, warc3-wet, cbor, zlib-state, unlzw3, trec-car-tools, lz4, ijson, inscriptis, ir-datasets, FlagEmbedding\n",
            "Successfully installed FlagEmbedding-1.3.5 cbor-1.0.0 ijson-3.4.0.post0 inscriptis-2.6.0 ir-datasets-0.5.11 lz4-4.4.5 trec-car-tools-2.6 unlzw3-0.2.3 warc3-wet-0.2.5 warc3-wet-clueweb09-0.2.5 zlib-state-0.1.10\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (0.17.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from peft) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from peft) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from peft) (6.0.3)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.12/dist-packages (from peft) (2.8.0+cu126)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (from peft) (4.57.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from peft) (4.67.1)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from peft) (1.11.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from peft) (0.6.2)\n",
            "Requirement already satisfied: huggingface_hub>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from peft) (0.36.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.25.0->peft) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.25.0->peft) (2025.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.25.0->peft) (2.32.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.25.0->peft) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.25.0->peft) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (80.9.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers->peft) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers->peft) (0.22.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (2025.10.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 리랭커준비\n",
        "\n",
        "from llama_index.postprocessor.flag_embedding_reranker import FlagEmbeddingReranker\n",
        "\n",
        "rerank = FlagEmbeddingReranker(\n",
        "    model=\"BAAI/bge-reranker-v2-m3\",\n",
        "    use_fp16=True,\n",
        "    top_n=2 #최상위 n 인자. 리랭커로 추출할 노드 수를 지정\n",
        ")\n",
        "\n",
        "# 쿼리 엔진\n",
        "query_engine = index.as_query_engine(\n",
        "    similarity_top_k=4,\n",
        "    node_postprocessors=[rerank]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5aVQOa8WlTV",
        "outputId": "eb0659fb-71d8-4fa9-ab9c-a84cdd5002f2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /BAAI/bge-reranker-v2-m3/resolve/main/tokenizer_config.json HTTP/1.1\" 307 0\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /api/resolve-cache/models/BAAI/bge-reranker-v2-m3/953dc6f6f85a1b2dbfca4c34a2796e7dde08d41e/tokenizer_config.json HTTP/1.1\" 200 0\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /api/models/BAAI/bge-reranker-v2-m3/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1\" 404 64\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /BAAI/bge-reranker-v2-m3/resolve/main/config.json HTTP/1.1\" 307 0\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /api/resolve-cache/models/BAAI/bge-reranker-v2-m3/953dc6f6f85a1b2dbfca4c34a2796e7dde08d41e/config.json HTTP/1.1\" 200 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"은비의 나이는?\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhNBeNDVXJbQ",
        "outputId": "2414f5d4-c181-454e-9455-62b7c0323441"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEBUG:llama_index.core.indices.utils:> Top 4 nodes:\n",
            "> [Node ad17e73a-4f61-4088-ad6e-7ebf175f8682] [Similarity score:                 0.536515] 1장: 밤의 도시, 네온 불빛 아래에서\r\n",
            "장소: 2077년, 밤의 도시, 네온 불빛이 가득한 뒷골목\r\n",
            "\r\n",
            "등장인물: 은비(17세, 해커), 잭(은비의 파트너, 전직 용병)\r\n",
            "...\n",
            "> [Node 07bee9e8-9773-480f-8222-086689aaa32c] [Similarity score:                 0.447299] 2장: 잭과의 만남, 위험한 동행\r\n",
            "장소: 은비의 은신처, 폐허가 된 건물\r\n",
            "\r\n",
            "은비는 낡은 건물의 지하실에 도착했다. 그곳에는 잭이 기다리고 있었다. 잭은 거대한 체구에 온...\n",
            "> [Node e4034cbf-7bbd-46fe-b4fc-af8b4cf6b4e4] [Similarity score:                 0.444639] 6장: 세상에 알리다\r\n",
            "장소: 은비의 블로그\r\n",
            "\r\n",
            "은비는 자신이 얻은 증거를 바탕으로 블로그에 글을 올렸다. 그녀의 글은 순식간에 퍼져나갔고, 아크 코퍼레이션의 비밀은 세상에...\n",
            "> [Node 3d8f51cc-e259-42df-bbfb-f00fff430eb2] [Similarity score:                 0.416877] 7장: 새로운 시작\r\n",
            "장소: 폐허가 된 건물\r\n",
            "\r\n",
            "은비와 잭은 다시 낡은 건물의 지하실로 돌아왔다. 그들은 세상을 바꾸기 위해 더 많은 일을 해야 한다는 것을 알고 있었다. ...\n",
            "INFO:google_genai.models:AFC is enabled with max remote calls: 10.\n",
            "DEBUG:httpcore.connection:close.started\n",
            "DEBUG:httpcore.connection:close.complete\n",
            "DEBUG:httpcore.connection:connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None\n",
            "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7b922c4d4b90>\n",
            "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x7b922cff0550> server_hostname='generativelanguage.googleapis.com' timeout=None\n",
            "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7b922c4d4f50>\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Mon, 17 Nov 2025 15:13:46 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=722'), (b'Transfer-Encoding', b'chunked')])\n",
            "INFO:httpx:HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n",
            "은비는 17세이다.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for node in response.source_nodes:\n",
        "  print(node.get_text())\n",
        "  print(\"--\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hx8Wta4pYC4T",
        "outputId": "a9655974-c6b2-4fb3-ce32-e283f1b0ac78"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1장: 밤의 도시, 네온 불빛 아래에서\r\n",
            "장소: 2077년, 밤의 도시, 네온 불빛이 가득한 뒷골목\r\n",
            "\r\n",
            "등장인물: 은비(17세, 해커), 잭(은비의 파트너, 전직 용병)\r\n",
            "\r\n",
            "은비는 오래된 코트를 덮어쓰고 낡은 건물 사이를 빠르게 이동했다. 그녀의 손에는 낡은 노트북, 눈에는 스마트 콘택트 렌즈가 장착되어 있었다. 은비는 도시의 어둠을 뚫고 빛나는 데이터의 바다를 헤엄치는 해커였다. 오늘밤 그녀의 목표는 거대 기업 '아크 코퍼레이션'의 보안 시스템을 뚫고, 불법적인 실험에 대한 증거를 찾아내는 것이었다.\n",
            "--\n",
            "2장: 잭과의 만남, 위험한 동행\r\n",
            "장소: 은비의 은신처, 폐허가 된 건물\r\n",
            "\r\n",
            "은비는 낡은 건물의 지하실에 도착했다. 그곳에는 잭이 기다리고 있었다. 잭은 거대한 체구에 온몸에 문신이 가득한 전직 용병이었다. 그는 은비의 해킹 능력을 높이 평가했고, 은비는 잭의 힘과 경험을 필요로 했다. 둘은 서로 다른 길을 걸어왔지만, 불의한 세상에 맞서 싸우는 공통의 목표를 가지고 있었다.\n",
            "--\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터로더\n",
        "- 라마허브에서 제공하는 데이터로더는 PDF, Word 등이나 웹 서비스 문서의 데이터 소스로 사용할 수 있다.\n",
        "- https://llamahub.ai/?tab=readers\n",
        "\n"
      ],
      "metadata": {
        "id": "U1BNiRKSYk8d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 웹페이지 질의 응답\n",
        "# BeautifulSoup: HTML, XML 문서를 해석하는 파이썬패키지\n",
        "!pip install llama-index-readers-web\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_c3JRSauY8GZ",
        "outputId": "838f4c33-d688-46ce-b5fb-8d78ce7c7886"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-index-readers-web\n",
            "  Downloading llama_index_readers_web-0.5.6-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: aiohttp<4,>=3.9.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-web) (3.13.2)\n",
            "Requirement already satisfied: beautifulsoup4<5,>=4.12.3 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-web) (4.13.5)\n",
            "Collecting chromedriver-autoinstaller<0.7,>=0.6.3 (from llama-index-readers-web)\n",
            "  Downloading chromedriver_autoinstaller-0.6.4-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: defusedxml<0.8,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-web) (0.7.1)\n",
            "Collecting firecrawl-py>=4.3.3 (from llama-index-readers-web)\n",
            "  Downloading firecrawl_py-4.8.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting html2text<2025,>=2024.2.26 (from llama-index-readers-web)\n",
            "  Downloading html2text-2024.2.26.tar.gz (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: httpx>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-web) (0.28.1)\n",
            "Requirement already satisfied: llama-index-core<0.15,>=0.13.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-web) (0.14.8)\n",
            "Collecting lxml-html-clean>=0.4.2 (from llama-index-readers-web)\n",
            "  Downloading lxml_html_clean-0.4.3-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: lxml>=5.4.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-web) (5.4.0)\n",
            "Collecting markdownify>=1.1.0 (from llama-index-readers-web)\n",
            "  Downloading markdownify-1.2.2-py3-none-any.whl.metadata (9.9 kB)\n",
            "Collecting newspaper3k<0.3,>=0.2.8 (from llama-index-readers-web)\n",
            "  Downloading newspaper3k-0.2.8-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting oxylabs>=2.0.0 (from llama-index-readers-web)\n",
            "  Downloading oxylabs-2.0.0-py3-none-any.whl.metadata (687 bytes)\n",
            "Collecting playwright<2.0,>=1.30 (from llama-index-readers-web)\n",
            "  Downloading playwright-1.56.0-py3-none-manylinux1_x86_64.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: requests<3,>=2.31.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-web) (2.32.4)\n",
            "Collecting scrapy>=2.10.0 (from llama-index-readers-web)\n",
            "  Downloading scrapy-2.13.4-py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting selenium<5,>=4.17.2 (from llama-index-readers-web)\n",
            "  Downloading selenium-4.38.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting spider-client<0.0.28,>=0.0.27 (from llama-index-readers-web)\n",
            "  Downloading spider-client-0.0.27.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: urllib3>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-web) (2.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.9.1->llama-index-readers-web) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.9.1->llama-index-readers-web) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.9.1->llama-index-readers-web) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.9.1->llama-index-readers-web) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.9.1->llama-index-readers-web) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.9.1->llama-index-readers-web) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.9.1->llama-index-readers-web) (1.22.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4<5,>=4.12.3->llama-index-readers-web) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4<5,>=4.12.3->llama-index-readers-web) (4.15.0)\n",
            "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.12/dist-packages (from chromedriver-autoinstaller<0.7,>=0.6.3->llama-index-readers-web) (25.0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (from firecrawl-py>=4.3.3->llama-index-readers-web) (1.2.1)\n",
            "Requirement already satisfied: websockets in /usr/local/lib/python3.12/dist-packages (from firecrawl-py>=4.3.3->llama-index-readers-web) (15.0.1)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (from firecrawl-py>=4.3.3->llama-index-readers-web) (1.6.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.12/dist-packages (from firecrawl-py>=4.3.3->llama-index-readers-web) (2.11.10)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->llama-index-readers-web) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->llama-index-readers-web) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->llama-index-readers-web) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->llama-index-readers-web) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.28.1->llama-index-readers-web) (0.16.0)\n",
            "Requirement already satisfied: aiosqlite in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-readers-web) (0.21.0)\n",
            "Requirement already satisfied: banks<3,>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-readers-web) (2.2.0)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-readers-web) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-readers-web) (1.3.1)\n",
            "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-readers-web) (1.0.8)\n",
            "Requirement already satisfied: filetype<2,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-readers-web) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-readers-web) (2025.3.0)\n",
            "Requirement already satisfied: llama-index-workflows!=2.9.0,<3,>=2 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-readers-web) (2.11.1)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-readers-web) (3.5)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-readers-web) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-readers-web) (1.26.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-readers-web) (10.4.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-readers-web) (4.5.0)\n",
            "Requirement already satisfied: pyyaml>=6.0.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-readers-web) (6.0.3)\n",
            "Requirement already satisfied: setuptools>=80.9.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-readers-web) (80.9.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.49 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15,>=0.13.0->llama-index-readers-web) (2.0.44)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-readers-web) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-readers-web) (0.12.0)\n",
            "Requirement already satisfied: tqdm<5,>=4.66.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-readers-web) (4.67.1)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-readers-web) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-readers-web) (2.0.1)\n",
            "Requirement already satisfied: six<2,>=1.15 in /usr/local/lib/python3.12/dist-packages (from markdownify>=1.1.0->llama-index-readers-web) (1.17.0)\n",
            "Collecting cssselect>=0.9.2 (from newspaper3k<0.3,>=0.2.8->llama-index-readers-web)\n",
            "  Downloading cssselect-1.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting feedparser>=5.2.1 (from newspaper3k<0.3,>=0.2.8->llama-index-readers-web)\n",
            "  Downloading feedparser-6.0.12-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting tldextract>=2.0.1 (from newspaper3k<0.3,>=0.2.8->llama-index-readers-web)\n",
            "  Downloading tldextract-5.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting feedfinder2>=0.0.4 (from newspaper3k<0.3,>=0.2.8->llama-index-readers-web)\n",
            "  Downloading feedfinder2-0.0.4.tar.gz (3.3 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jieba3k>=0.35.1 (from newspaper3k<0.3,>=0.2.8->llama-index-readers-web)\n",
            "  Downloading jieba3k-0.35.1.zip (7.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from newspaper3k<0.3,>=0.2.8->llama-index-readers-web) (2.9.0.post0)\n",
            "Collecting tinysegmenter==0.3 (from newspaper3k<0.3,>=0.2.8->llama-index-readers-web)\n",
            "  Downloading tinysegmenter-0.3.tar.gz (16 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pyee<14,>=13 (from playwright<2.0,>=1.30->llama-index-readers-web)\n",
            "  Downloading pyee-13.0.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: greenlet<4.0.0,>=3.1.1 in /usr/local/lib/python3.12/dist-packages (from playwright<2.0,>=1.30->llama-index-readers-web) (3.2.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.31.0->llama-index-readers-web) (3.4.4)\n",
            "Requirement already satisfied: cryptography>=37.0.0 in /usr/local/lib/python3.12/dist-packages (from scrapy>=2.10.0->llama-index-readers-web) (43.0.3)\n",
            "Collecting itemadapter>=0.1.0 (from scrapy>=2.10.0->llama-index-readers-web)\n",
            "  Downloading itemadapter-0.12.2-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting itemloaders>=1.0.1 (from scrapy>=2.10.0->llama-index-readers-web)\n",
            "  Downloading itemloaders-1.3.2-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting parsel>=1.5.0 (from scrapy>=2.10.0->llama-index-readers-web)\n",
            "  Downloading parsel-1.10.0-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Collecting protego>=0.1.15 (from scrapy>=2.10.0->llama-index-readers-web)\n",
            "  Downloading protego-0.5.0-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting pydispatcher>=2.0.5 (from scrapy>=2.10.0->llama-index-readers-web)\n",
            "  Downloading PyDispatcher-2.0.7-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: pyopenssl>=22.0.0 in /usr/local/lib/python3.12/dist-packages (from scrapy>=2.10.0->llama-index-readers-web) (24.2.1)\n",
            "Collecting queuelib>=1.4.2 (from scrapy>=2.10.0->llama-index-readers-web)\n",
            "  Downloading queuelib-1.8.0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting service-identity>=18.1.0 (from scrapy>=2.10.0->llama-index-readers-web)\n",
            "  Downloading service_identity-24.2.0-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting twisted<=25.5.0,>=21.7.0 (from scrapy>=2.10.0->llama-index-readers-web)\n",
            "  Downloading twisted-25.5.0-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting w3lib>=1.17.0 (from scrapy>=2.10.0->llama-index-readers-web)\n",
            "  Downloading w3lib-2.3.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting zope-interface>=5.1.0 (from scrapy>=2.10.0->llama-index-readers-web)\n",
            "  Downloading zope_interface-8.1.1-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting trio<1.0,>=0.31.0 (from selenium<5,>=4.17.2->llama-index-readers-web)\n",
            "  Downloading trio-0.32.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting trio-websocket<1.0,>=0.12.2 (from selenium<5,>=4.17.2->llama-index-readers-web)\n",
            "  Downloading trio_websocket-0.12.2-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: websocket-client<2.0,>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from selenium<5,>=4.17.2->llama-index-readers-web) (1.9.0)\n",
            "Requirement already satisfied: griffe in /usr/local/lib/python3.12/dist-packages (from banks<3,>=2.2.0->llama-index-core<0.15,>=0.13.0->llama-index-readers-web) (1.15.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from banks<3,>=2.2.0->llama-index-core<0.15,>=0.13.0->llama-index-readers-web) (3.1.6)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=37.0.0->scrapy>=2.10.0->llama-index-readers-web) (2.0.0)\n",
            "Collecting sgmllib3k (from feedparser>=5.2.1->newspaper3k<0.3,>=0.2.8->llama-index-readers-web)\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jmespath>=0.9.5 (from itemloaders>=1.0.1->scrapy>=2.10.0->llama-index-readers-web)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-workflows!=2.9.0,<3,>=2->llama-index-core<0.15,>=0.13.0->llama-index-readers-web) (0.4.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama-index-core<0.15,>=0.13.0->llama-index-readers-web) (8.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama-index-core<0.15,>=0.13.0->llama-index-readers-web) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama-index-core<0.15,>=0.13.0->llama-index-readers-web) (2024.11.6)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->firecrawl-py>=4.3.3->llama-index-readers-web) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->firecrawl-py>=4.3.3->llama-index-readers-web) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->firecrawl-py>=4.3.3->llama-index-readers-web) (0.4.2)\n",
            "Requirement already satisfied: pyasn1 in /usr/local/lib/python3.12/dist-packages (from service-identity>=18.1.0->scrapy>=2.10.0->llama-index-readers-web) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules in /usr/local/lib/python3.12/dist-packages (from service-identity>=18.1.0->scrapy>=2.10.0->llama-index-readers-web) (0.4.2)\n",
            "Collecting requests-file>=1.4 (from tldextract>=2.0.1->newspaper3k<0.3,>=0.2.8->llama-index-readers-web)\n",
            "  Downloading requests_file-3.0.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.12/dist-packages (from tldextract>=2.0.1->newspaper3k<0.3,>=0.2.8->llama-index-readers-web) (3.20.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.31.0->selenium<5,>=4.17.2->llama-index-readers-web) (2.4.0)\n",
            "Collecting outcome (from trio<1.0,>=0.31.0->selenium<5,>=4.17.2->llama-index-readers-web)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.31.0->selenium<5,>=4.17.2->llama-index-readers-web) (1.3.1)\n",
            "Collecting wsproto>=0.14 (from trio-websocket<1.0,>=0.12.2->selenium<5,>=4.17.2->llama-index-readers-web)\n",
            "  Downloading wsproto-1.3.1-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting automat>=24.8.0 (from twisted<=25.5.0,>=21.7.0->scrapy>=2.10.0->llama-index-readers-web)\n",
            "  Downloading automat-25.4.16-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting constantly>=15.1 (from twisted<=25.5.0,>=21.7.0->scrapy>=2.10.0->llama-index-readers-web)\n",
            "  Downloading constantly-23.10.4-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting hyperlink>=17.1.1 (from twisted<=25.5.0,>=21.7.0->scrapy>=2.10.0->llama-index-readers-web)\n",
            "  Downloading hyperlink-21.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting incremental>=24.7.0 (from twisted<=25.5.0,>=21.7.0->scrapy>=2.10.0->llama-index-readers-web)\n",
            "  Downloading incremental-24.7.2-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.15,>=0.13.0->llama-index-readers-web) (1.1.0)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from urllib3[socks]<3.0,>=2.5.0->selenium<5,>=4.17.2->llama-index-readers-web) (1.7.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json->llama-index-core<0.15,>=0.13.0->llama-index-readers-web) (3.26.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=37.0.0->scrapy>=2.10.0->llama-index-readers-web) (2.23)\n",
            "Requirement already satisfied: colorama>=0.4 in /usr/local/lib/python3.12/dist-packages (from griffe->banks<3,>=2.2.0->llama-index-core<0.15,>=0.13.0->llama-index-readers-web) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->banks<3,>=2.2.0->llama-index-core<0.15,>=0.13.0->llama-index-readers-web) (3.0.3)\n",
            "Downloading llama_index_readers_web-0.5.6-py3-none-any.whl (118 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.7/118.7 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chromedriver_autoinstaller-0.6.4-py3-none-any.whl (7.6 kB)\n",
            "Downloading firecrawl_py-4.8.0-py3-none-any.whl (188 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.8/188.8 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lxml_html_clean-0.4.3-py3-none-any.whl (14 kB)\n",
            "Downloading markdownify-1.2.2-py3-none-any.whl (15 kB)\n",
            "Downloading newspaper3k-0.2.8-py3-none-any.whl (211 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.1/211.1 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading oxylabs-2.0.0-py3-none-any.whl (34 kB)\n",
            "Downloading playwright-1.56.0-py3-none-manylinux1_x86_64.whl (46.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.3/46.3 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scrapy-2.13.4-py3-none-any.whl (321 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.6/321.6 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading selenium-4.38.0-py3-none-any.whl (9.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m89.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cssselect-1.3.0-py3-none-any.whl (18 kB)\n",
            "Downloading feedparser-6.0.12-py3-none-any.whl (81 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.5/81.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading itemadapter-0.12.2-py3-none-any.whl (18 kB)\n",
            "Downloading itemloaders-1.3.2-py3-none-any.whl (12 kB)\n",
            "Downloading parsel-1.10.0-py2.py3-none-any.whl (17 kB)\n",
            "Downloading protego-0.5.0-py3-none-any.whl (10 kB)\n",
            "Downloading PyDispatcher-2.0.7-py3-none-any.whl (12 kB)\n",
            "Downloading pyee-13.0.0-py3-none-any.whl (15 kB)\n",
            "Downloading queuelib-1.8.0-py3-none-any.whl (13 kB)\n",
            "Downloading service_identity-24.2.0-py3-none-any.whl (11 kB)\n",
            "Downloading tldextract-5.3.0-py3-none-any.whl (107 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.4/107.4 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio-0.32.0-py3-none-any.whl (512 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m512.0/512.0 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n",
            "Downloading twisted-25.5.0-py3-none-any.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading w3lib-2.3.1-py3-none-any.whl (21 kB)\n",
            "Downloading zope_interface-8.1.1-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (264 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.7/264.7 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading automat-25.4.16-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading constantly-23.10.4-py3-none-any.whl (13 kB)\n",
            "Downloading hyperlink-21.0.0-py2.py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.6/74.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading incremental-24.7.2-py3-none-any.whl (20 kB)\n",
            "Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading requests_file-3.0.1-py2.py3-none-any.whl (4.5 kB)\n",
            "Downloading wsproto-1.3.1-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: html2text, tinysegmenter, spider-client, feedfinder2, jieba3k, sgmllib3k\n",
            "  Building wheel for html2text (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for html2text: filename=html2text-2024.2.26-py3-none-any.whl size=33168 sha256=dcc5c1322df2f40e1138334e06d1f73cae287a87316107d81748a46cee11a1b0\n",
            "  Stored in directory: /root/.cache/pip/wheels/2b/01/23/578505d65e2a97d78bf1fe3fc8256ecf37572dc1df598b0eaf\n",
            "  Building wheel for tinysegmenter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tinysegmenter: filename=tinysegmenter-0.3-py3-none-any.whl size=13634 sha256=9499790ced85e431560921c6675c6e5e0b144ea6d331c50386854c5a69b3fc02\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/91/9f/00d66475960891a64867914273fcaf78df6cb04d905b104a2a\n",
            "  Building wheel for spider-client (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for spider-client: filename=spider_client-0.0.27-py3-none-any.whl size=6052 sha256=ce13a32108ffcf01ccc3b09f032c5ffe0205fc319442cf6bab970e0b55a40553\n",
            "  Stored in directory: /root/.cache/pip/wheels/6c/41/42/4155300999390be7e455a6b05c602849f5810bf9383c43adb2\n",
            "  Building wheel for feedfinder2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for feedfinder2: filename=feedfinder2-0.0.4-py3-none-any.whl size=3393 sha256=b8faad2f0d6f31c013914a104b041579d14d0d25cea5d30433e85f40ade4aa2b\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/9f/fb/364871d7426d3cdd4d293dcf7e53d97f160c508b2ccf00cc79\n",
            "  Building wheel for jieba3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jieba3k: filename=jieba3k-0.35.1-py3-none-any.whl size=7398402 sha256=3219ccd062085e5bffb9f2e65d045174647b39ad6f0397c2ab69acb5113640b2\n",
            "  Stored in directory: /root/.cache/pip/wheels/26/72/f7/fff392a8d4ea988dea4ccf9788599d09462a7f5e51e04f8a92\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6089 sha256=7688f6fd3592c933481d5f2f6e13b2d4c2aa6f403dc7ae546faf57125640569e\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/f5/1a/23761066dac1d0e8e683e5fdb27e12de53209d05a4a37e6246\n",
            "Successfully built html2text tinysegmenter spider-client feedfinder2 jieba3k sgmllib3k\n",
            "Installing collected packages: tinysegmenter, sgmllib3k, pydispatcher, jieba3k, zope-interface, wsproto, w3lib, queuelib, pyee, protego, outcome, lxml-html-clean, jmespath, itemadapter, incremental, hyperlink, html2text, feedparser, cssselect, constantly, chromedriver-autoinstaller, automat, twisted, trio, spider-client, requests-file, playwright, parsel, markdownify, feedfinder2, trio-websocket, tldextract, service-identity, oxylabs, itemloaders, firecrawl-py, selenium, scrapy, newspaper3k, llama-index-readers-web\n",
            "Successfully installed automat-25.4.16 chromedriver-autoinstaller-0.6.4 constantly-23.10.4 cssselect-1.3.0 feedfinder2-0.0.4 feedparser-6.0.12 firecrawl-py-4.8.0 html2text-2024.2.26 hyperlink-21.0.0 incremental-24.7.2 itemadapter-0.12.2 itemloaders-1.3.2 jieba3k-0.35.1 jmespath-1.0.1 llama-index-readers-web-0.5.6 lxml-html-clean-0.4.3 markdownify-1.2.2 newspaper3k-0.2.8 outcome-1.3.0.post0 oxylabs-2.0.0 parsel-1.10.0 playwright-1.56.0 protego-0.5.0 pydispatcher-2.0.7 pyee-13.0.0 queuelib-1.8.0 requests-file-3.0.1 scrapy-2.13.4 selenium-4.38.0 service-identity-24.2.0 sgmllib3k-1.0.0 spider-client-0.0.27 tinysegmenter-0.3 tldextract-5.3.0 trio-0.32.0 trio-websocket-0.12.2 twisted-25.5.0 w3lib-2.3.1 wsproto-1.3.1 zope-interface-8.1.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.12/pathlib.py:404: RuntimeWarning: coroutine 'prepare_chat_params' was never awaited\n",
            "  parsed = [sys.intern(str(x)) for x in rel.split(sep) if x and x != '.']\n",
            "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "llama_index"
                ]
              },
              "id": "e64c1563909b40f69e0ffad7555dbf9c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.readers.web import BeautifulSoupWebReader\n",
        "\n",
        "reader = BeautifulSoupWebReader()\n",
        "\n",
        "documents = reader.load_data(urls=[\"https://naver.com\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAkWXaFWZSM8",
        "outputId": "1459f8d7-9da7-487b-b79b-fcb58e384ef6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): naver.com:443\n",
            "DEBUG:urllib3.connectionpool:https://naver.com:443 \"GET / HTTP/1.1\" 301 None\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): www.naver.com:443\n",
            "DEBUG:urllib3.connectionpool:https://www.naver.com:443 \"GET / HTTP/1.1\" 200 31198\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import VectorStoreIndex\n",
        "\n",
        "# 인덱스, 쿼리 엔진 준비\n",
        "index = VectorStoreIndex.from_documents(documents)\n",
        "query_engine = index.as_query_engine()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVTG4AcVZgcG",
        "outputId": "25d04f95-b526-43a1-8be4-9eea631d560e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: NAVER                          \n",
            "   상단영역 바로가기 서비...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"네이버에 대해 알려주세요\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "or6oUU8wZpZS",
        "outputId": "c32a56d7-a4ce-46f2-857f-949ed946fc20"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEBUG:llama_index.core.indices.utils:> Top 1 nodes:\n",
            "> [Node 7913505f-dfa7-4df1-9676-275a46be8611] [Similarity score:                 0.598344] NAVER                          \n",
            "   상단영역 바로가기 서비스 메뉴 바로가기 새소식 블록 바로가기 쇼핑 블록 바로가기 관심사 블록 바로가기 MY 영역...\n",
            "INFO:google_genai.models:AFC is enabled with max remote calls: 10.\n",
            "DEBUG:httpcore.connection:close.started\n",
            "DEBUG:httpcore.connection:close.complete\n",
            "DEBUG:httpcore.connection:connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None\n",
            "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7b922924a390>\n",
            "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x7b922cff0550> server_hostname='generativelanguage.googleapis.com' timeout=None\n",
            "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7b922aad5280>\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Mon, 17 Nov 2025 15:20:33 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=785'), (b'Transfer-Encoding', b'chunked')])\n",
            "INFO:httpx:HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n",
            "네이버는 검색, 입력 도구 및 다양한 블록(새소식, 쇼핑, 관심사)과 MY 영역, 위젯 보드를 제공하는 서비스입니다.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 벡터 스토어\n",
        "- 벡터 스토어는 문서의 청크와 임베딩 벡터를 저장하는 공간\n",
        "- 기본 벡터스토어는 인메모리 저장소. `vector_store.persist()` 호출하여 디스크에 데이터를 영구적으로 저장 가능\n",
        "- 라마인덱스는 많은 벡터 스토어를 지원. (대표적으로 파이스 ,파인콘)"
      ],
      "metadata": {
        "id": "6Mgaql82c5fi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 평가\n",
        "- RAG 성능을 향상시키려면 다양한 파라미터를 평가하여 더 성능을 이끌 수 있도록 파라미터를 조정해야한다.\n",
        "- 라마인덱스는 두 가지 평가를 수행하는 도구를 제공한다.\n",
        "  - 검색 성능 평가(Retrieval Evaluation): 벡터 스토어에서 얻는 컨텍스트(청크) 품질을 평가한다. 리트리버(검색도구)를 사용하여 기대하는 컨텍스트를 얻을 수 있는지 측정한다.\n",
        "  - 응답 성능 평가(Response Evaluation): 쿼리 엔진이 생성하는 응답 품질을 평가. 환각 현상이 없는지 측정\n",
        "  - https://developers.llamaindex.ai/python/framework/module_guides/evaluating/"
      ],
      "metadata": {
        "id": "w5HghsEOfWeT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import Settings\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from llama_index.llms.google_genai import GoogleGenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "import logging\n",
        "import sys\n",
        "logging.basicConfig(stream=sys.stdout, level=logging.DEBUG, force=True)\n",
        "\n",
        "# LLM 모델 준비\n",
        "Settings.llm = GoogleGenAI(\n",
        "    model_name=\"models/gemini-2.5-flash\",\n",
        "    api_key=userdata.get('GOOGLE_API_KEY'),\n",
        "    safety_settings={\n",
        "        \"HARM_CATEGORY_HARASSMENT\": \"BLOCK_NONE\",\n",
        "        \"HARM_CATEGORY_HATE_SPEECH\": \"BLOCK_NONE\",\n",
        "        \"HARM_CATEGORY_SEXUALLY_EXPLICIT\": \"BLOCK_NONE\",\n",
        "        \"HARM_CATEGORY_DANGEROUS_CONTENT\": \"BLOCK_NONE\"\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndW08fHtf8sj",
        "outputId": "97730049-e564-4f09-9489-0e64e7a0fc9a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEBUG:httpcore.connection:connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None\n",
            "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7a9e58d48200>\n",
            "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x7a9e58d436d0> server_hostname='generativelanguage.googleapis.com' timeout=None\n",
            "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7a9e58a088f0>\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'GET']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'GET']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'GET']>\n",
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Mon, 17 Nov 2025 15:48:15 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=204'), (b'Transfer-Encoding', b'chunked')])\n",
            "INFO:httpx:HTTP Request: GET https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash \"HTTP/1.1 200 OK\"\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'GET']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import SimpleDirectoryReader\n",
        "\n",
        "documents = SimpleDirectoryReader('./data').load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2JNtTasgD-Y",
        "outputId": "667ea7cd-8aac-4e3b-db04-774693a7d4fd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEBUG:llama_index.core.readers.file.base:> [SimpleDirectoryReader] Total files added: 7\n",
            "DEBUG:fsspec.local:open file: /content/data/redhood1.txt\n",
            "DEBUG:fsspec.local:open file: /content/data/redhood2.txt\n",
            "DEBUG:fsspec.local:open file: /content/data/redhood3.txt\n",
            "DEBUG:fsspec.local:open file: /content/data/redhood4.txt\n",
            "DEBUG:fsspec.local:open file: /content/data/redhood5.txt\n",
            "DEBUG:fsspec.local:open file: /content/data/redhood6.txt\n",
            "DEBUG:fsspec.local:open file: /content/data/redhood7.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 문서에서 노드 가져오고 ID 지정\n",
        "\n",
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "\n",
        "node_parser = SentenceSplitter()\n",
        "nodes = node_parser.get_nodes_from_documents(documents)\n",
        "\n",
        "for idx, node in enumerate(nodes):\n",
        "  node.id_ = f\"node_{idx}\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BS-D4hTcgMz_",
        "outputId": "c7b9470a-b60e-46b3-ea08-bc36445798d6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 1장: 밤의 도시, 네온 불빛 아래에서\r\n",
            "장소: 2077년, 밤의 도시, 네온 불빛이...\n",
            "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 2장: 잭과의 만남, 위험한 동행\n",
            "장소: 은비의 은신처, 폐허가 된 건물\n",
            "\n",
            "은비...\n",
            "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 3장: 아크 코퍼레이션 잠입 작전\n",
            "장소: 아크 코퍼레이션 본사, 최첨단 보안 시스템...\n",
            "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 4장: 데이터의 바다에서 진실을 찾아서\n",
            "장소: 아크 코퍼레이션 데이터 센터\n",
            "\n",
            "은...\n",
            "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 5장: 추격과 탈출\n",
            "장소: 도시의 뒷골목, 고속도로\n",
            "\n",
            "아크 코퍼레이션의 추격대가...\n",
            "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 6장: 세상에 알리다\n",
            "장소: 은비의 블로그\n",
            "\n",
            "은비는 자신이 얻은 증거를 바탕으로...\n",
            "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 7장: 새로운 시작\n",
            "장소: 폐허가 된 건물\n",
            "\n",
            "은비와 잭은 다시 낡은 건물의 지하...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 질문 컨텍스트 데이터셋 생성\n",
        "\n",
        "# 한국어 템플릿을 준비\n",
        "\n",
        "from llama_index.core.evaluation import generate_question_context_pairs\n",
        "from llama_index.llms.google_genai import GoogleGenAI\n",
        "\n",
        "DEFAULT_QA_GENERATE_PROMPT_TMPL = \"\"\"컨텍스트 정보는 아래와 같습니다.\n",
        "\n",
        "-----------------\n",
        "{context_str}\n",
        "-----------------\n",
        "\n",
        "예비 지식이 없고 문맥 정보가 주어진 경우,\n",
        "아래 쿼리를 기반으로 문제만을 생성합니다.\n",
        "\n",
        "당신은 선생님입니다.\n",
        "당신의 작업은 향후 시험용으로 {num_questions_per_chunk} 개의 질문을 작성하는 것입니다.\n",
        "문제는 문서 전체에 걸쳐 다양해야 합니다.\n",
        "설문은 제공된 컨텍스트 정보로 한정해주세요\"\"\"\n",
        "\n",
        "qa_dataset = generate_question_context_pairs(\n",
        "    nodes,\n",
        "    llm=Settings.llm,\n",
        "    num_questions_per_chunk=2,\n",
        "    qa_generate_prompt_tmpl=DEFAULT_QA_GENERATE_PROMPT_TMPL\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmDm8rJHgdF4",
        "outputId": "40892fc1-d8b5-4638-b1e7-181ff961f424"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/7 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:google_genai.models:AFC is enabled with max remote calls: 10.\n",
            "DEBUG:httpcore.connection:close.started\n",
            "DEBUG:httpcore.connection:close.complete\n",
            "DEBUG:httpcore.connection:connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None\n",
            "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7a9e58242630>\n",
            "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x7a9e58d436d0> server_hostname='generativelanguage.googleapis.com' timeout=None\n",
            "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7a9fcaf90a70>\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Mon, 17 Nov 2025 15:55:40 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=2049'), (b'Transfer-Encoding', b'chunked')])\n",
            "INFO:httpx:HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 1/7 [00:02<00:12,  2.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:google_genai.models:AFC is enabled with max remote calls: 10.\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Mon, 17 Nov 2025 15:55:41 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1160'), (b'Transfer-Encoding', b'chunked')])\n",
            "INFO:httpx:HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▊       | 2/7 [00:03<00:07,  1.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:google_genai.models:AFC is enabled with max remote calls: 10.\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Mon, 17 Nov 2025 15:55:43 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1672'), (b'Transfer-Encoding', b'chunked')])\n",
            "INFO:httpx:HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 3/7 [00:04<00:06,  1.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:google_genai.models:AFC is enabled with max remote calls: 10.\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Mon, 17 Nov 2025 15:55:44 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1782'), (b'Transfer-Encoding', b'chunked')])\n",
            "INFO:httpx:HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 4/7 [00:06<00:05,  1.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:google_genai.models:AFC is enabled with max remote calls: 10.\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Mon, 17 Nov 2025 15:55:46 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1217'), (b'Transfer-Encoding', b'chunked')])\n",
            "INFO:httpx:HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████▏  | 5/7 [00:08<00:03,  1.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:google_genai.models:AFC is enabled with max remote calls: 10.\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Mon, 17 Nov 2025 15:55:47 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1206'), (b'Transfer-Encoding', b'chunked')])\n",
            "INFO:httpx:HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 6/7 [00:09<00:01,  1.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:google_genai.models:AFC is enabled with max remote calls: 10.\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Mon, 17 Nov 2025 15:55:48 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1169'), (b'Transfer-Encoding', b'chunked')])\n",
            "INFO:httpx:HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7/7 [00:10<00:00,  1.49s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 질문 컨텍스트 데이터셋 저장\n",
        "qa_dataset.save_json(\"pg_eval_dataset.json\")"
      ],
      "metadata": {
        "id": "wjkw2u0uh7-4"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 불러오기\n",
        "from llama_index.core.evaluation import EmbeddingQAFinetuneDataset\n",
        "\n",
        "qa_dataset = EmbeddingQAFinetuneDataset.from_json(\"pg_eval_dataset.json\")"
      ],
      "metadata": {
        "id": "G7h87prSiD2O"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for key in list(qa_dataset.queries.keys()):\n",
        "  print(\"queries\", qa_dataset.queries[key])\n",
        "  print(\"relevant_docs\", qa_dataset.relevant_docs[key])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orxFknk2iMrD",
        "outputId": "bbf00491-55ba-4260-da23-aee401d9ef9b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "queries 알겠습니다. 2077년 밤의 도시를 배경으로 한 제시된 컨텍스트 정보를 바탕으로 시험 문제 2개를 출제하겠습니다.\n",
            "relevant_docs ['node_0']\n",
            "queries **문제 1:**\n",
            "relevant_docs ['node_0']\n",
            "queries ## 시험 문제 (2문제)\n",
            "relevant_docs ['node_1']\n",
            "queries 은비와 잭이 만나게 된 장소는 어디이며, 그곳의 분위기를 묘사하시오. (5점)\n",
            "relevant_docs ['node_1']\n",
            "queries ## 아크 코퍼레이션 잠입 작전 시험 문제 (총 2문제)\n",
            "relevant_docs ['node_2']\n",
            "queries **1. 은비와 잭이 아크 코퍼레이션 본사에 잠입했을 때, 각자 어떤 역할을 수행하여 잠입을 도왔는지 구체적으로 설명하시오.** (10점)\n",
            "relevant_docs ['node_2']\n",
            "queries ## 아크 코퍼레이션 데이터 센터 관련 시험 문제 (총 2문제)\n",
            "relevant_docs ['node_3']\n",
            "queries **1. 은비가 아크 코퍼레이션 데이터 센터에서 발견한 '충격적인 증거'는 구체적으로 무엇이었으며, 이 증거가 은비에게 어떤 영향을 미쳤는지 서술하시오.** (배점: 5점)\n",
            "relevant_docs ['node_3']\n",
            "queries ## 시험 문제 (5장: 추격과 탈출)\n",
            "relevant_docs ['node_4']\n",
            "queries **1. 은비와 잭은 아크 코퍼레이션의 추격대를 어떻게 따돌렸나요? 그들의 방법 각각을 구체적으로 설명하시오. (5점)**\n",
            "relevant_docs ['node_4']\n",
            "queries ## 시험 문제 (6장: 세상에 알리다)\n",
            "relevant_docs ['node_5']\n",
            "queries **1. 은비가 블로그에 글을 올린 후 발생한 결과는 무엇이며, 그 이유는 무엇이라고 생각하십니까? (5점)**\n",
            "relevant_docs ['node_5']\n",
            "queries ## 시험 문제 (7장: 새로운 시작)\n",
            "relevant_docs ['node_6']\n",
            "queries 은비와 잭이 낡은 건물 지하실로 다시 돌아온 이유는 무엇이며, 그들의 마음가짐을 묘사하시오. (5점)\n",
            "relevant_docs ['node_6']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 검색 성능 평가(Retrieval Evaluation)\n",
        "\n",
        "from llama_index.core import VectorStoreIndex, Settings\n",
        "\n",
        "\n",
        "Settings.embed_model = HuggingFaceEmbedding(\n",
        "    model_name=\"BAAI/bge-m3\"\n",
        ")\n",
        "\n",
        "vector_index = VectorStoreIndex(nodes, embed_model=Settings.embed_model)\n",
        "retriever = vector_index.as_retriever(similarity_top_k=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nf4H3CUgipiI",
        "outputId": "1ed5cc2f-d064-45ab-eb04-271ccaf7237c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: BAAI/bge-m3\n",
            "DEBUG:urllib3.connectionpool:Resetting dropped connection: huggingface.co\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /BAAI/bge-m3/resolve/main/modules.json HTTP/1.1\" 307 0\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /api/resolve-cache/models/BAAI/bge-m3/5617a9f61b028005a4858fdac845db406aefb181/modules.json HTTP/1.1\" 200 0\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /BAAI/bge-m3/resolve/main/config_sentence_transformers.json HTTP/1.1\" 307 0\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /api/resolve-cache/models/BAAI/bge-m3/5617a9f61b028005a4858fdac845db406aefb181/config_sentence_transformers.json HTTP/1.1\" 200 0\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /BAAI/bge-m3/resolve/main/config_sentence_transformers.json HTTP/1.1\" 307 0\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /api/resolve-cache/models/BAAI/bge-m3/5617a9f61b028005a4858fdac845db406aefb181/config_sentence_transformers.json HTTP/1.1\" 200 0\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /BAAI/bge-m3/resolve/main/README.md HTTP/1.1\" 307 0\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /api/resolve-cache/models/BAAI/bge-m3/5617a9f61b028005a4858fdac845db406aefb181/README.md HTTP/1.1\" 200 0\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /BAAI/bge-m3/resolve/main/modules.json HTTP/1.1\" 307 0\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /api/resolve-cache/models/BAAI/bge-m3/5617a9f61b028005a4858fdac845db406aefb181/modules.json HTTP/1.1\" 200 0\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /BAAI/bge-m3/resolve/main/sentence_bert_config.json HTTP/1.1\" 307 0\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /api/resolve-cache/models/BAAI/bge-m3/5617a9f61b028005a4858fdac845db406aefb181/sentence_bert_config.json HTTP/1.1\" 200 0\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /BAAI/bge-m3/resolve/main/adapter_config.json HTTP/1.1\" 404 0\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /BAAI/bge-m3/resolve/main/config.json HTTP/1.1\" 307 0\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /api/resolve-cache/models/BAAI/bge-m3/5617a9f61b028005a4858fdac845db406aefb181/config.json HTTP/1.1\" 200 0\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /BAAI/bge-m3/resolve/main/model.safetensors HTTP/1.1\" 404 0\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /api/models/BAAI/bge-m3 HTTP/1.1\" 200 5134\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /api/models/BAAI/bge-m3/commits/main HTTP/1.1\" 200 9525\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /api/models/BAAI/bge-m3/discussions?p=0 HTTP/1.1\" 200 30543\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /api/models/BAAI/bge-m3/commits/refs%2Fpr%2F130 HTTP/1.1\" 200 10490\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /BAAI/bge-m3/resolve/refs%2Fpr%2F130/model.safetensors.index.json HTTP/1.1\" 404 0\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /BAAI/bge-m3/resolve/refs%2Fpr%2F130/model.safetensors HTTP/1.1\" 302 0\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /BAAI/bge-m3/resolve/main/tokenizer_config.json HTTP/1.1\" 307 0\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /api/resolve-cache/models/BAAI/bge-m3/5617a9f61b028005a4858fdac845db406aefb181/tokenizer_config.json HTTP/1.1\" 200 0\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /api/models/BAAI/bge-m3/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1\" 404 64\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /BAAI/bge-m3/resolve/main/1_Pooling/config.json HTTP/1.1\" 307 0\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /api/resolve-cache/models/BAAI/bge-m3/5617a9f61b028005a4858fdac845db406aefb181/1_Pooling%2Fconfig.json HTTP/1.1\" 200 0\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /api/models/BAAI/bge-m3 HTTP/1.1\" 200 5134\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 검색 성능 평가기 준비\n",
        "from llama_index.core.evaluation import RetrieverEvaluator\n",
        "\n",
        "retriever_evaluator = RetrieverEvaluator.from_metric_names(\n",
        "    [\"mrr\", \"hit_rate\"],\n",
        "    # mrr: 각 쿼리 최상위에 있는 관련 문서를 조사하여 시스템 정확도를 평가하는 지표. 올바른 답의 랭크가 한 번이라면 1, 두번이라면 0.5, 세 번이라면 0.333\n",
        "    # hit_rate: 취득한 상위 k개의 컨텍스트 내에 올바른 답이 포함되어 있는 비율계산 포함 1, 미포함 0\n",
        "    retriever=retriever\n",
        ")"
      ],
      "metadata": {
        "id": "XgXTYwPhi4As"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 평가 실행\n",
        "\n",
        "mrr_values = []\n",
        "hit_rate_values = []\n",
        "\n",
        "for key in list(qa_dataset.queries.keys()):\n",
        "  # 한 개의 쿼리 평가 실행\n",
        "  result = retriever_evaluator.evaluate(\n",
        "      query=qa_dataset.queries[key],\n",
        "      expected_ids=qa_dataset.relevant_docs[key]\n",
        "  )\n",
        "\n",
        "  # 집계\n",
        "  mrr_values.append(result.metric_dict[\"mrr\"].score)\n",
        "  hit_rate_values.append(result.metric_dict[\"hit_rate\"].score)\n",
        "\n",
        "  print(result)\n",
        "\n",
        "mrr_average = sum(mrr_values) / len(mrr_values)\n",
        "hit_rate_average = sum(hit_rate_values) / len(hit_rate_values)\n",
        "\n",
        "print(f\"MRR: {mrr_average}\")\n",
        "print(f\"Hit Rate: {hit_rate_average}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8Lgif6FkO81",
        "outputId": "635d3652-23c9-4331-8529-f9178f831887"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEBUG:asyncio:Using selector: EpollSelector\n",
            "DEBUG:llama_index.core.indices.utils:> Top 3 nodes:\n",
            "> [Node node_0] [Similarity score:                 0.5335] 1장: 밤의 도시, 네온 불빛 아래에서\n",
            "장소: 2077년, 밤의 도시, 네온 불빛이 가득한 뒷골목\n",
            "\n",
            "등장인물: 은비(17세, 해커), 잭(은비의 파트너, 전직 용병)\n",
            "...\n",
            "> [Node node_6] [Similarity score:                 0.449401] 7장: 새로운 시작\n",
            "장소: 폐허가 된 건물\n",
            "\n",
            "은비와 잭은 다시 낡은 건물의 지하실로 돌아왔다. 그들은 세상을 바꾸기 위해 더 많은 일을 해야 한다는 것을 알고 있었다. ...\n",
            "> [Node node_1] [Similarity score:                 0.365035] 2장: 잭과의 만남, 위험한 동행\n",
            "장소: 은비의 은신처, 폐허가 된 건물\n",
            "\n",
            "은비는 낡은 건물의 지하실에 도착했다. 그곳에는 잭이 기다리고 있었다. 잭은 거대한 체구에 온...\n",
            "Query: 알겠습니다. 2077년 밤의 도시를 배경으로 한 제시된 컨텍스트 정보를 바탕으로 시험 문제 2개를 출제하겠습니다.\n",
            "Metrics: {'mrr': 1.0, 'hit_rate': 1.0}\n",
            "\n",
            "DEBUG:asyncio:Using selector: EpollSelector\n",
            "DEBUG:llama_index.core.indices.utils:> Top 3 nodes:\n",
            "> [Node node_0] [Similarity score:                 0.417968] 1장: 밤의 도시, 네온 불빛 아래에서\n",
            "장소: 2077년, 밤의 도시, 네온 불빛이 가득한 뒷골목\n",
            "\n",
            "등장인물: 은비(17세, 해커), 잭(은비의 파트너, 전직 용병)\n",
            "...\n",
            "> [Node node_3] [Similarity score:                 0.355809] 4장: 데이터의 바다에서 진실을 찾아서\n",
            "장소: 아크 코퍼레이션 데이터 센터\n",
            "\n",
            "은비는 데이터의 바다를 헤엄치며 숨겨진 파일들을 찾아냈다. 그곳에는 아크 코퍼레이션이 인간을...\n",
            "> [Node node_6] [Similarity score:                 0.35413] 7장: 새로운 시작\n",
            "장소: 폐허가 된 건물\n",
            "\n",
            "은비와 잭은 다시 낡은 건물의 지하실로 돌아왔다. 그들은 세상을 바꾸기 위해 더 많은 일을 해야 한다는 것을 알고 있었다. ...\n",
            "Query: **문제 1:**\n",
            "Metrics: {'mrr': 1.0, 'hit_rate': 1.0}\n",
            "\n",
            "DEBUG:asyncio:Using selector: EpollSelector\n",
            "DEBUG:llama_index.core.indices.utils:> Top 3 nodes:\n",
            "> [Node node_1] [Similarity score:                 0.374071] 2장: 잭과의 만남, 위험한 동행\n",
            "장소: 은비의 은신처, 폐허가 된 건물\n",
            "\n",
            "은비는 낡은 건물의 지하실에 도착했다. 그곳에는 잭이 기다리고 있었다. 잭은 거대한 체구에 온...\n",
            "> [Node node_0] [Similarity score:                 0.355625] 1장: 밤의 도시, 네온 불빛 아래에서\n",
            "장소: 2077년, 밤의 도시, 네온 불빛이 가득한 뒷골목\n",
            "\n",
            "등장인물: 은비(17세, 해커), 잭(은비의 파트너, 전직 용병)\n",
            "...\n",
            "> [Node node_6] [Similarity score:                 0.341173] 7장: 새로운 시작\n",
            "장소: 폐허가 된 건물\n",
            "\n",
            "은비와 잭은 다시 낡은 건물의 지하실로 돌아왔다. 그들은 세상을 바꾸기 위해 더 많은 일을 해야 한다는 것을 알고 있었다. ...\n",
            "Query: ## 시험 문제 (2문제)\n",
            "Metrics: {'mrr': 1.0, 'hit_rate': 1.0}\n",
            "\n",
            "DEBUG:asyncio:Using selector: EpollSelector\n",
            "DEBUG:llama_index.core.indices.utils:> Top 3 nodes:\n",
            "> [Node node_1] [Similarity score:                 0.582718] 2장: 잭과의 만남, 위험한 동행\n",
            "장소: 은비의 은신처, 폐허가 된 건물\n",
            "\n",
            "은비는 낡은 건물의 지하실에 도착했다. 그곳에는 잭이 기다리고 있었다. 잭은 거대한 체구에 온...\n",
            "> [Node node_4] [Similarity score:                 0.561788] 5장: 추격과 탈출\n",
            "장소: 도시의 뒷골목, 고속도로\n",
            "\n",
            "아크 코퍼레이션의 추격대가 은비와 잭을 뒤쫓았다. 둘은 도시를 가로지르는 고속도로에서 격렬한 추격전을 벌였다. 은비...\n",
            "> [Node node_6] [Similarity score:                 0.540849] 7장: 새로운 시작\n",
            "장소: 폐허가 된 건물\n",
            "\n",
            "은비와 잭은 다시 낡은 건물의 지하실로 돌아왔다. 그들은 세상을 바꾸기 위해 더 많은 일을 해야 한다는 것을 알고 있었다. ...\n",
            "Query: 은비와 잭이 만나게 된 장소는 어디이며, 그곳의 분위기를 묘사하시오. (5점)\n",
            "Metrics: {'mrr': 1.0, 'hit_rate': 1.0}\n",
            "\n",
            "DEBUG:asyncio:Using selector: EpollSelector\n",
            "DEBUG:llama_index.core.indices.utils:> Top 3 nodes:\n",
            "> [Node node_2] [Similarity score:                 0.524386] 3장: 아크 코퍼레이션 잠입 작전\n",
            "장소: 아크 코퍼레이션 본사, 최첨단 보안 시스템\n",
            "\n",
            "은비와 잭은 아크 코퍼레이션 본사에 잠입했다. 은비는 자신의 해킹 능력을 이용해 보...\n",
            "> [Node node_1] [Similarity score:                 0.410316] 2장: 잭과의 만남, 위험한 동행\n",
            "장소: 은비의 은신처, 폐허가 된 건물\n",
            "\n",
            "은비는 낡은 건물의 지하실에 도착했다. 그곳에는 잭이 기다리고 있었다. 잭은 거대한 체구에 온...\n",
            "> [Node node_3] [Similarity score:                 0.40177] 4장: 데이터의 바다에서 진실을 찾아서\n",
            "장소: 아크 코퍼레이션 데이터 센터\n",
            "\n",
            "은비는 데이터의 바다를 헤엄치며 숨겨진 파일들을 찾아냈다. 그곳에는 아크 코퍼레이션이 인간을...\n",
            "Query: ## 아크 코퍼레이션 잠입 작전 시험 문제 (총 2문제)\n",
            "Metrics: {'mrr': 1.0, 'hit_rate': 1.0}\n",
            "\n",
            "DEBUG:asyncio:Using selector: EpollSelector\n",
            "DEBUG:llama_index.core.indices.utils:> Top 3 nodes:\n",
            "> [Node node_2] [Similarity score:                 0.690648] 3장: 아크 코퍼레이션 잠입 작전\n",
            "장소: 아크 코퍼레이션 본사, 최첨단 보안 시스템\n",
            "\n",
            "은비와 잭은 아크 코퍼레이션 본사에 잠입했다. 은비는 자신의 해킹 능력을 이용해 보...\n",
            "> [Node node_4] [Similarity score:                 0.535904] 5장: 추격과 탈출\n",
            "장소: 도시의 뒷골목, 고속도로\n",
            "\n",
            "아크 코퍼레이션의 추격대가 은비와 잭을 뒤쫓았다. 둘은 도시를 가로지르는 고속도로에서 격렬한 추격전을 벌였다. 은비...\n",
            "> [Node node_5] [Similarity score:                 0.534656] 6장: 세상에 알리다\n",
            "장소: 은비의 블로그\n",
            "\n",
            "은비는 자신이 얻은 증거를 바탕으로 블로그에 글을 올렸다. 그녀의 글은 순식간에 퍼져나갔고, 아크 코퍼레이션의 비밀은 세상에...\n",
            "Query: **1. 은비와 잭이 아크 코퍼레이션 본사에 잠입했을 때, 각자 어떤 역할을 수행하여 잠입을 도왔는지 구체적으로 설명하시오.** (10점)\n",
            "Metrics: {'mrr': 1.0, 'hit_rate': 1.0}\n",
            "\n",
            "DEBUG:asyncio:Using selector: EpollSelector\n",
            "DEBUG:llama_index.core.indices.utils:> Top 3 nodes:\n",
            "> [Node node_3] [Similarity score:                 0.484637] 4장: 데이터의 바다에서 진실을 찾아서\n",
            "장소: 아크 코퍼레이션 데이터 센터\n",
            "\n",
            "은비는 데이터의 바다를 헤엄치며 숨겨진 파일들을 찾아냈다. 그곳에는 아크 코퍼레이션이 인간을...\n",
            "> [Node node_2] [Similarity score:                 0.468473] 3장: 아크 코퍼레이션 잠입 작전\n",
            "장소: 아크 코퍼레이션 본사, 최첨단 보안 시스템\n",
            "\n",
            "은비와 잭은 아크 코퍼레이션 본사에 잠입했다. 은비는 자신의 해킹 능력을 이용해 보...\n",
            "> [Node node_5] [Similarity score:                 0.390771] 6장: 세상에 알리다\n",
            "장소: 은비의 블로그\n",
            "\n",
            "은비는 자신이 얻은 증거를 바탕으로 블로그에 글을 올렸다. 그녀의 글은 순식간에 퍼져나갔고, 아크 코퍼레이션의 비밀은 세상에...\n",
            "Query: ## 아크 코퍼레이션 데이터 센터 관련 시험 문제 (총 2문제)\n",
            "Metrics: {'mrr': 1.0, 'hit_rate': 1.0}\n",
            "\n",
            "DEBUG:asyncio:Using selector: EpollSelector\n",
            "DEBUG:llama_index.core.indices.utils:> Top 3 nodes:\n",
            "> [Node node_5] [Similarity score:                 0.61119] 6장: 세상에 알리다\n",
            "장소: 은비의 블로그\n",
            "\n",
            "은비는 자신이 얻은 증거를 바탕으로 블로그에 글을 올렸다. 그녀의 글은 순식간에 퍼져나갔고, 아크 코퍼레이션의 비밀은 세상에...\n",
            "> [Node node_3] [Similarity score:                 0.604751] 4장: 데이터의 바다에서 진실을 찾아서\n",
            "장소: 아크 코퍼레이션 데이터 센터\n",
            "\n",
            "은비는 데이터의 바다를 헤엄치며 숨겨진 파일들을 찾아냈다. 그곳에는 아크 코퍼레이션이 인간을...\n",
            "> [Node node_2] [Similarity score:                 0.549519] 3장: 아크 코퍼레이션 잠입 작전\n",
            "장소: 아크 코퍼레이션 본사, 최첨단 보안 시스템\n",
            "\n",
            "은비와 잭은 아크 코퍼레이션 본사에 잠입했다. 은비는 자신의 해킹 능력을 이용해 보...\n",
            "Query: **1. 은비가 아크 코퍼레이션 데이터 센터에서 발견한 '충격적인 증거'는 구체적으로 무엇이었으며, 이 증거가 은비에게 어떤 영향을 미쳤는지 서술하시오.** (배점: 5점)\n",
            "Metrics: {'mrr': 0.5, 'hit_rate': 1.0}\n",
            "\n",
            "DEBUG:asyncio:Using selector: EpollSelector\n",
            "DEBUG:llama_index.core.indices.utils:> Top 3 nodes:\n",
            "> [Node node_4] [Similarity score:                 0.65293] 5장: 추격과 탈출\n",
            "장소: 도시의 뒷골목, 고속도로\n",
            "\n",
            "아크 코퍼레이션의 추격대가 은비와 잭을 뒤쫓았다. 둘은 도시를 가로지르는 고속도로에서 격렬한 추격전을 벌였다. 은비...\n",
            "> [Node node_2] [Similarity score:                 0.430849] 3장: 아크 코퍼레이션 잠입 작전\n",
            "장소: 아크 코퍼레이션 본사, 최첨단 보안 시스템\n",
            "\n",
            "은비와 잭은 아크 코퍼레이션 본사에 잠입했다. 은비는 자신의 해킹 능력을 이용해 보...\n",
            "> [Node node_1] [Similarity score:                 0.42768] 2장: 잭과의 만남, 위험한 동행\n",
            "장소: 은비의 은신처, 폐허가 된 건물\n",
            "\n",
            "은비는 낡은 건물의 지하실에 도착했다. 그곳에는 잭이 기다리고 있었다. 잭은 거대한 체구에 온...\n",
            "Query: ## 시험 문제 (5장: 추격과 탈출)\n",
            "Metrics: {'mrr': 1.0, 'hit_rate': 1.0}\n",
            "\n",
            "DEBUG:asyncio:Using selector: EpollSelector\n",
            "DEBUG:llama_index.core.indices.utils:> Top 3 nodes:\n",
            "> [Node node_4] [Similarity score:                 0.711602] 5장: 추격과 탈출\n",
            "장소: 도시의 뒷골목, 고속도로\n",
            "\n",
            "아크 코퍼레이션의 추격대가 은비와 잭을 뒤쫓았다. 둘은 도시를 가로지르는 고속도로에서 격렬한 추격전을 벌였다. 은비...\n",
            "> [Node node_2] [Similarity score:                 0.594981] 3장: 아크 코퍼레이션 잠입 작전\n",
            "장소: 아크 코퍼레이션 본사, 최첨단 보안 시스템\n",
            "\n",
            "은비와 잭은 아크 코퍼레이션 본사에 잠입했다. 은비는 자신의 해킹 능력을 이용해 보...\n",
            "> [Node node_5] [Similarity score:                 0.547906] 6장: 세상에 알리다\n",
            "장소: 은비의 블로그\n",
            "\n",
            "은비는 자신이 얻은 증거를 바탕으로 블로그에 글을 올렸다. 그녀의 글은 순식간에 퍼져나갔고, 아크 코퍼레이션의 비밀은 세상에...\n",
            "Query: **1. 은비와 잭은 아크 코퍼레이션의 추격대를 어떻게 따돌렸나요? 그들의 방법 각각을 구체적으로 설명하시오. (5점)**\n",
            "Metrics: {'mrr': 1.0, 'hit_rate': 1.0}\n",
            "\n",
            "DEBUG:asyncio:Using selector: EpollSelector\n",
            "DEBUG:llama_index.core.indices.utils:> Top 3 nodes:\n",
            "> [Node node_5] [Similarity score:                 0.57997] 6장: 세상에 알리다\n",
            "장소: 은비의 블로그\n",
            "\n",
            "은비는 자신이 얻은 증거를 바탕으로 블로그에 글을 올렸다. 그녀의 글은 순식간에 퍼져나갔고, 아크 코퍼레이션의 비밀은 세상에...\n",
            "> [Node node_3] [Similarity score:                 0.402877] 4장: 데이터의 바다에서 진실을 찾아서\n",
            "장소: 아크 코퍼레이션 데이터 센터\n",
            "\n",
            "은비는 데이터의 바다를 헤엄치며 숨겨진 파일들을 찾아냈다. 그곳에는 아크 코퍼레이션이 인간을...\n",
            "> [Node node_6] [Similarity score:                 0.398001] 7장: 새로운 시작\n",
            "장소: 폐허가 된 건물\n",
            "\n",
            "은비와 잭은 다시 낡은 건물의 지하실로 돌아왔다. 그들은 세상을 바꾸기 위해 더 많은 일을 해야 한다는 것을 알고 있었다. ...\n",
            "Query: ## 시험 문제 (6장: 세상에 알리다)\n",
            "Metrics: {'mrr': 1.0, 'hit_rate': 1.0}\n",
            "\n",
            "DEBUG:asyncio:Using selector: EpollSelector\n",
            "DEBUG:llama_index.core.indices.utils:> Top 3 nodes:\n",
            "> [Node node_5] [Similarity score:                 0.609339] 6장: 세상에 알리다\n",
            "장소: 은비의 블로그\n",
            "\n",
            "은비는 자신이 얻은 증거를 바탕으로 블로그에 글을 올렸다. 그녀의 글은 순식간에 퍼져나갔고, 아크 코퍼레이션의 비밀은 세상에...\n",
            "> [Node node_4] [Similarity score:                 0.479531] 5장: 추격과 탈출\n",
            "장소: 도시의 뒷골목, 고속도로\n",
            "\n",
            "아크 코퍼레이션의 추격대가 은비와 잭을 뒤쫓았다. 둘은 도시를 가로지르는 고속도로에서 격렬한 추격전을 벌였다. 은비...\n",
            "> [Node node_0] [Similarity score:                 0.46539] 1장: 밤의 도시, 네온 불빛 아래에서\n",
            "장소: 2077년, 밤의 도시, 네온 불빛이 가득한 뒷골목\n",
            "\n",
            "등장인물: 은비(17세, 해커), 잭(은비의 파트너, 전직 용병)\n",
            "...\n",
            "Query: **1. 은비가 블로그에 글을 올린 후 발생한 결과는 무엇이며, 그 이유는 무엇이라고 생각하십니까? (5점)**\n",
            "Metrics: {'mrr': 1.0, 'hit_rate': 1.0}\n",
            "\n",
            "DEBUG:asyncio:Using selector: EpollSelector\n",
            "DEBUG:llama_index.core.indices.utils:> Top 3 nodes:\n",
            "> [Node node_6] [Similarity score:                 0.587958] 7장: 새로운 시작\n",
            "장소: 폐허가 된 건물\n",
            "\n",
            "은비와 잭은 다시 낡은 건물의 지하실로 돌아왔다. 그들은 세상을 바꾸기 위해 더 많은 일을 해야 한다는 것을 알고 있었다. ...\n",
            "> [Node node_0] [Similarity score:                 0.413393] 1장: 밤의 도시, 네온 불빛 아래에서\n",
            "장소: 2077년, 밤의 도시, 네온 불빛이 가득한 뒷골목\n",
            "\n",
            "등장인물: 은비(17세, 해커), 잭(은비의 파트너, 전직 용병)\n",
            "...\n",
            "> [Node node_3] [Similarity score:                 0.408355] 4장: 데이터의 바다에서 진실을 찾아서\n",
            "장소: 아크 코퍼레이션 데이터 센터\n",
            "\n",
            "은비는 데이터의 바다를 헤엄치며 숨겨진 파일들을 찾아냈다. 그곳에는 아크 코퍼레이션이 인간을...\n",
            "Query: ## 시험 문제 (7장: 새로운 시작)\n",
            "Metrics: {'mrr': 1.0, 'hit_rate': 1.0}\n",
            "\n",
            "DEBUG:asyncio:Using selector: EpollSelector\n",
            "DEBUG:llama_index.core.indices.utils:> Top 3 nodes:\n",
            "> [Node node_6] [Similarity score:                 0.668532] 7장: 새로운 시작\n",
            "장소: 폐허가 된 건물\n",
            "\n",
            "은비와 잭은 다시 낡은 건물의 지하실로 돌아왔다. 그들은 세상을 바꾸기 위해 더 많은 일을 해야 한다는 것을 알고 있었다. ...\n",
            "> [Node node_1] [Similarity score:                 0.623509] 2장: 잭과의 만남, 위험한 동행\n",
            "장소: 은비의 은신처, 폐허가 된 건물\n",
            "\n",
            "은비는 낡은 건물의 지하실에 도착했다. 그곳에는 잭이 기다리고 있었다. 잭은 거대한 체구에 온...\n",
            "> [Node node_4] [Similarity score:                 0.530053] 5장: 추격과 탈출\n",
            "장소: 도시의 뒷골목, 고속도로\n",
            "\n",
            "아크 코퍼레이션의 추격대가 은비와 잭을 뒤쫓았다. 둘은 도시를 가로지르는 고속도로에서 격렬한 추격전을 벌였다. 은비...\n",
            "Query: 은비와 잭이 낡은 건물 지하실로 다시 돌아온 이유는 무엇이며, 그들의 마음가짐을 묘사하시오. (5점)\n",
            "Metrics: {'mrr': 1.0, 'hit_rate': 1.0}\n",
            "\n",
            "MRR: 0.9642857142857143\n",
            "Hit Rate: 1.0\n"
          ]
        }
      ]
    }
  ]
}